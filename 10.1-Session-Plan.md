# Session 10.1: Foundation Infrastructure

**Parent Plan**: `10-Session-Plan-Production.md`
**Target**: ~50-60k tokens
**Prerequisites**: Existing codebase compiles (`cargo check --workspace`)

---

## Scope

This session implements the foundational infrastructure that all other components depend on:

1. **Dependencies** (Part 13) - Add required crates to Cargo.toml
2. **Request Context** (Part 1) - Correlation IDs for distributed tracing
3. **Circuit Breaker** (Part 2) - Database resilience pattern
4. **Error Infrastructure** (Part 3) - Enhanced error types with From impls
5. **Retry Logic** (Part 4) - Exponential backoff with jitter

---

## Implementation Order

### Step 1: Update Dependencies

**File**: `backend/crates/pm-ws/Cargo.toml`

Add to `[dependencies]`:
```toml
base64 = "0.22"
serde_json = "1.0"
rand = "0.8"
```

Add to `[dev-dependencies]`:
```toml
proptest = "1.4"
```

**Verification**: `cargo check -p pm-ws`

---

### Step 2: Create Request Context

**Create**: `backend/crates/pm-ws/src/request_context.rs`

```rust
use std::sync::atomic::{AtomicU64, Ordering};
use uuid::Uuid;

static REQUEST_COUNTER: AtomicU64 = AtomicU64::new(0);

/// Request context for correlation and tracing
#[derive(Debug, Clone)]
pub struct RequestContext {
    /// Unique correlation ID for this request chain
    pub correlation_id: String,
    /// Sequence number within this server instance
    pub request_seq: u64,
    /// User making the request
    pub user_id: Uuid,
    /// Connection ID for WebSocket tracking
    pub connection_id: String,
    /// Start time for latency tracking
    pub started_at: std::time::Instant,
}

impl RequestContext {
    pub fn new(user_id: Uuid, connection_id: String, message_id: &str) -> Self {
        let request_seq = REQUEST_COUNTER.fetch_add(1, Ordering::SeqCst);

        // Use message_id as correlation_id if provided, otherwise generate
        let correlation_id = if message_id.is_empty() {
            format!("req-{}-{}", request_seq, Uuid::new_v4().as_simple())
        } else {
            message_id.to_string()
        };

        Self {
            correlation_id,
            request_seq,
            user_id,
            connection_id,
            started_at: std::time::Instant::now(),
        }
    }

    /// Get elapsed time since request started
    pub fn elapsed_ms(&self) -> u64 {
        self.started_at.elapsed().as_millis() as u64
    }

    /// Create a log prefix for structured logging
    pub fn log_prefix(&self) -> String {
        format!(
            "[req={} user={} conn={}]",
            &self.correlation_id[..8.min(self.correlation_id.len())],
            &self.user_id.to_string()[..8],
            &self.connection_id[..8.min(self.connection_id.len())]
        )
    }
}
```

---

### Step 3: Create Structured Logger

**Create**: `backend/crates/pm-ws/src/tracing.rs`

```rust
use crate::RequestContext;
use log::{debug, error, info, warn};

/// Structured logging with request context
pub struct RequestLogger<'a> {
    ctx: &'a RequestContext,
}

impl<'a> RequestLogger<'a> {
    pub fn new(ctx: &'a RequestContext) -> Self {
        Self { ctx }
    }

    pub fn info(&self, message: &str) {
        info!("{} {}", self.ctx.log_prefix(), message);
    }

    pub fn debug(&self, message: &str) {
        debug!("{} {}", self.ctx.log_prefix(), message);
    }

    pub fn warn(&self, message: &str) {
        warn!("{} {}", self.ctx.log_prefix(), message);
    }

    pub fn error(&self, message: &str) {
        error!("{} {}", self.ctx.log_prefix(), message);
    }

    pub fn info_with_duration(&self, message: &str) {
        info!(
            "{} {} ({}ms)",
            self.ctx.log_prefix(),
            message,
            self.ctx.elapsed_ms()
        );
    }

    pub fn error_with_duration(&self, message: &str) {
        error!(
            "{} {} ({}ms)",
            self.ctx.log_prefix(),
            message,
            self.ctx.elapsed_ms()
        );
    }
}

/// Log a handler entry point
#[macro_export]
macro_rules! log_handler_entry {
    ($ctx:expr, $handler:expr) => {
        log::debug!(
            "{} -> {} handler",
            $ctx.log_prefix(),
            $handler
        );
    };
}

/// Log a handler exit with duration
#[macro_export]
macro_rules! log_handler_exit {
    ($ctx:expr, $handler:expr, $result:expr) => {
        match &$result {
            Ok(_) => log::info!(
                "{} <- {} OK ({}ms)",
                $ctx.log_prefix(),
                $handler,
                $ctx.elapsed_ms()
            ),
            Err(e) => log::warn!(
                "{} <- {} ERR: {} ({}ms)",
                $ctx.log_prefix(),
                $handler,
                e,
                $ctx.elapsed_ms()
            ),
        }
    };
}
```

**Update**: `backend/crates/pm-ws/src/lib.rs`

Add these lines (placement depends on existing structure):
```rust
mod request_context;
mod tracing;

pub use request_context::RequestContext;
pub use tracing::RequestLogger;
```

**Verification**: `cargo check -p pm-ws`

---

### Step 4: Create Circuit Breaker

**Create**: `backend/crates/pm-ws/src/circuit_breaker.rs`

```rust
use std::sync::atomic::{AtomicU32, AtomicU64, Ordering};
use std::sync::RwLock;
use std::time::{Duration, Instant};

/// Circuit breaker states
#[derive(Debug, Clone, Copy, PartialEq)]
pub enum CircuitState {
    /// Normal operation - requests flow through
    Closed,
    /// Too many failures - requests rejected immediately
    Open,
    /// Testing if service recovered - limited requests allowed
    HalfOpen,
}

/// Circuit breaker configuration
#[derive(Debug, Clone)]
pub struct CircuitBreakerConfig {
    /// Number of failures before opening circuit
    pub failure_threshold: u32,
    /// Duration to keep circuit open before testing
    pub open_duration: Duration,
    /// Number of successful requests in half-open to close circuit
    pub half_open_success_threshold: u32,
    /// Window for counting failures
    pub failure_window: Duration,
}

impl Default for CircuitBreakerConfig {
    fn default() -> Self {
        Self {
            failure_threshold: 5,
            open_duration: Duration::from_secs(30),
            half_open_success_threshold: 3,
            failure_window: Duration::from_secs(60),
        }
    }
}

/// Thread-safe circuit breaker
pub struct CircuitBreaker {
    config: CircuitBreakerConfig,
    state: RwLock<CircuitState>,
    failure_count: AtomicU32,
    success_count: AtomicU32,
    last_failure_time: AtomicU64,
    opened_at: AtomicU64,
}

impl CircuitBreaker {
    pub fn new(config: CircuitBreakerConfig) -> Self {
        Self {
            config,
            state: RwLock::new(CircuitState::Closed),
            failure_count: AtomicU32::new(0),
            success_count: AtomicU32::new(0),
            last_failure_time: AtomicU64::new(0),
            opened_at: AtomicU64::new(0),
        }
    }

    /// Check if request should be allowed
    pub fn allow_request(&self) -> Result<(), CircuitBreakerError> {
        let state = *self.state.read().unwrap();

        match state {
            CircuitState::Closed => Ok(()),
            CircuitState::Open => {
                // Check if we should transition to half-open
                let opened_at = self.opened_at.load(Ordering::SeqCst);
                let now = Instant::now().elapsed().as_secs();

                if now - opened_at >= self.config.open_duration.as_secs() {
                    // Transition to half-open
                    let mut state_guard = self.state.write().unwrap();
                    if *state_guard == CircuitState::Open {
                        *state_guard = CircuitState::HalfOpen;
                        self.success_count.store(0, Ordering::SeqCst);
                        log::info!("Circuit breaker transitioning to HalfOpen");
                    }
                    Ok(())
                } else {
                    Err(CircuitBreakerError::CircuitOpen {
                        retry_after_secs: self.config.open_duration.as_secs()
                            - (now - opened_at),
                    })
                }
            }
            CircuitState::HalfOpen => Ok(()), // Allow limited requests in half-open
        }
    }

    /// Record a successful request
    pub fn record_success(&self) {
        let state = *self.state.read().unwrap();

        match state {
            CircuitState::Closed => {
                // Reset failure count on success
                self.failure_count.store(0, Ordering::SeqCst);
            }
            CircuitState::HalfOpen => {
                let successes = self.success_count.fetch_add(1, Ordering::SeqCst) + 1;
                if successes >= self.config.half_open_success_threshold {
                    // Close the circuit
                    let mut state_guard = self.state.write().unwrap();
                    *state_guard = CircuitState::Closed;
                    self.failure_count.store(0, Ordering::SeqCst);
                    log::info!("Circuit breaker closed after {} successes", successes);
                }
            }
            CircuitState::Open => {} // Shouldn't happen, but ignore
        }
    }

    /// Record a failed request
    pub fn record_failure(&self) {
        let now = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_secs();

        let last_failure = self.last_failure_time.load(Ordering::SeqCst);

        // Reset count if outside failure window
        if now - last_failure > self.config.failure_window.as_secs() {
            self.failure_count.store(0, Ordering::SeqCst);
        }

        self.last_failure_time.store(now, Ordering::SeqCst);
        let failures = self.failure_count.fetch_add(1, Ordering::SeqCst) + 1;

        let state = *self.state.read().unwrap();

        match state {
            CircuitState::Closed => {
                if failures >= self.config.failure_threshold {
                    // Open the circuit
                    let mut state_guard = self.state.write().unwrap();
                    *state_guard = CircuitState::Open;
                    self.opened_at.store(
                        Instant::now().elapsed().as_secs(),
                        Ordering::SeqCst,
                    );
                    log::warn!(
                        "Circuit breaker OPEN after {} failures",
                        failures
                    );
                }
            }
            CircuitState::HalfOpen => {
                // Single failure in half-open reopens circuit
                let mut state_guard = self.state.write().unwrap();
                *state_guard = CircuitState::Open;
                self.opened_at.store(
                    Instant::now().elapsed().as_secs(),
                    Ordering::SeqCst,
                );
                log::warn!("Circuit breaker reopened due to failure in HalfOpen state");
            }
            CircuitState::Open => {} // Already open
        }
    }

    /// Get current state
    pub fn state(&self) -> CircuitState {
        *self.state.read().unwrap()
    }
}

#[derive(Debug, Clone)]
pub enum CircuitBreakerError {
    CircuitOpen { retry_after_secs: u64 },
}

impl std::fmt::Display for CircuitBreakerError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            Self::CircuitOpen { retry_after_secs } => {
                write!(f, "Circuit breaker open. Retry after {} seconds", retry_after_secs)
            }
        }
    }
}

impl std::error::Error for CircuitBreakerError {}
```

**Update**: `backend/crates/pm-ws/src/lib.rs`

Add:
```rust
mod circuit_breaker;

pub use circuit_breaker::{CircuitBreaker, CircuitBreakerConfig, CircuitState};
```

**Verification**: `cargo check -p pm-ws`

---

### Step 5: Update Error Infrastructure

**File**: `backend/crates/pm-ws/src/error.rs`

This is a **replacement** of the existing error.rs. The key additions are:
- `Database` error variant
- `ServiceUnavailable` error variant (for circuit breaker)
- `Timeout` error variant
- `From<CircuitBreakerError>` impl
- `From<sqlx::Error>` impl
- `From<pm_db::DbError>` impl
- `is_retryable()` method

```rust
use std::panic::Location;
use error_location::ErrorLocation;
use thiserror::Error;
use crate::circuit_breaker::CircuitBreakerError;

#[derive(Error, Debug)]
pub enum WsError {
    #[error("Connection closed: {reason} {location}")]
    ConnectionClosed {
        reason: String,
        location: ErrorLocation,
    },

    #[error("Protobuf decode failed: {source} {location}")]
    ProtoDecode {
        #[source]
        source: prost::DecodeError,
        location: ErrorLocation,
    },

    #[error("Protobuf encode failed: {source} {location}")]
    ProtoEncode {
        #[source]
        source: prost::EncodeError,
        location: ErrorLocation,
    },

    #[error("Send buffer full, client too slow {location}")]
    SendBufferFull { location: ErrorLocation },

    #[error("Broadcast channel lagged, missed {missed_count} messages {location}")]
    BroadcastLagged {
        missed_count: u64,
        location: ErrorLocation,
    },

    #[error("Connection limit exceeded: {current} connections (max: {max}) {location}")]
    ConnectionLimitExceeded {
        current: usize,
        max: usize,
        location: ErrorLocation,
    },

    #[error("Invalid message: {message} {location}")]
    InvalidMessage {
        message: String,
        location: ErrorLocation,
    },

    #[error("Heartbeat timeout after {timeout_secs}s {location}")]
    HeartbeatTimeout {
        timeout_secs: u64,
        location: ErrorLocation,
    },

    #[error("Internal error: {message} {location}")]
    Internal {
        message: String,
        location: ErrorLocation,
    },

    #[error("Validation failed: {message}")]
    ValidationError {
        message: String,
        field: Option<String>,
        location: ErrorLocation,
    },

    #[error("Resource not found: {message}")]
    NotFound {
        message: String,
        location: ErrorLocation,
    },

    #[error("Conflict: resource was modified (current version: {current_version})")]
    ConflictError {
        current_version: i32,
        location: ErrorLocation,
    },

    #[error("Cannot delete: {message}")]
    DeleteBlocked {
        message: String,
        location: ErrorLocation,
    },

    #[error("Unauthorized: {message}")]
    Unauthorized {
        message: String,
        location: ErrorLocation,
    },

    // NEW: Database error with details
    #[error("Database error: {message}")]
    Database {
        message: String,
        location: ErrorLocation,
    },

    // NEW: Service unavailable (circuit breaker open)
    #[error("Service temporarily unavailable. Retry after {retry_after_secs} seconds")]
    ServiceUnavailable {
        retry_after_secs: u64,
        location: ErrorLocation,
    },

    // NEW: Request timeout
    #[error("Request timed out after {timeout_secs} seconds")]
    Timeout {
        timeout_secs: u64,
        location: ErrorLocation,
    },
}

impl WsError {
    /// Convert to protobuf Error for client
    pub fn to_proto_error(&self) -> pm_proto::Error {
        pm_proto::Error {
            code: self.error_code().to_string(),
            message: self.to_string(),
            field: match self {
                Self::ValidationError { field, .. } => field.clone(),
                _ => None,
            },
        }
    }

    fn error_code(&self) -> &'static str {
        match self {
            Self::ConnectionClosed { .. } => "CONNECTION_CLOSED",
            Self::ProtoDecode { .. } => "DECODE_ERROR",
            Self::ProtoEncode { .. } => "ENCODE_ERROR",
            Self::SendBufferFull { .. } => "SLOW_CLIENT",
            Self::BroadcastLagged { .. } => "BROADCAST_LAGGED",
            Self::ConnectionLimitExceeded { .. } => "CONNECTION_LIMIT",
            Self::InvalidMessage { .. } => "INVALID_MESSAGE",
            Self::HeartbeatTimeout { .. } => "HEARTBEAT_TIMEOUT",
            Self::Internal { .. } => "INTERNAL_ERROR",
            Self::ValidationError { .. } => "VALIDATION_ERROR",
            Self::NotFound { .. } => "NOT_FOUND",
            Self::ConflictError { .. } => "CONFLICT",
            Self::DeleteBlocked { .. } => "DELETE_BLOCKED",
            Self::Unauthorized { .. } => "UNAUTHORIZED",
            Self::Database { .. } => "DATABASE_ERROR",
            Self::ServiceUnavailable { .. } => "SERVICE_UNAVAILABLE",
            Self::Timeout { .. } => "TIMEOUT",
        }
    }

    /// Check if this error is retryable
    pub fn is_retryable(&self) -> bool {
        matches!(
            self,
            Self::Database { .. }
                | Self::ServiceUnavailable { .. }
                | Self::Timeout { .. }
        )
    }
}

impl From<prost::DecodeError> for WsError {
    #[track_caller]
    fn from(source: prost::DecodeError) -> Self {
        Self::ProtoDecode {
            source,
            location: ErrorLocation::from(Location::caller()),
        }
    }
}

impl From<prost::EncodeError> for WsError {
    #[track_caller]
    fn from(source: prost::EncodeError) -> Self {
        Self::ProtoEncode {
            source,
            location: ErrorLocation::from(Location::caller()),
        }
    }
}

impl From<pm_db::DbError> for WsError {
    #[track_caller]
    fn from(err: pm_db::DbError) -> Self {
        Self::Database {
            message: err.to_string(),
            location: ErrorLocation::from(Location::caller()),
        }
    }
}

impl From<sqlx::Error> for WsError {
    #[track_caller]
    fn from(err: sqlx::Error) -> Self {
        Self::Database {
            message: err.to_string(),
            location: ErrorLocation::from(Location::caller()),
        }
    }
}

impl From<CircuitBreakerError> for WsError {
    #[track_caller]
    fn from(err: CircuitBreakerError) -> Self {
        match err {
            CircuitBreakerError::CircuitOpen { retry_after_secs } => {
                Self::ServiceUnavailable {
                    retry_after_secs,
                    location: ErrorLocation::from(Location::caller()),
                }
            }
        }
    }
}

pub type Result<T> = std::result::Result<T, WsError>;
```

**Note**: Compare with existing `error.rs` first. Only add new variants and impls, don't remove existing ones that are in use.

**Verification**: `cargo check -p pm-ws`

---

### Step 6: Create Retry Logic

**Create**: `backend/crates/pm-ws/src/retry.rs`

```rust
use std::time::Duration;
use tokio::time::sleep;

/// Configuration for retry behavior
#[derive(Debug, Clone)]
pub struct RetryConfig {
    /// Maximum number of retry attempts
    pub max_attempts: u32,
    /// Initial delay before first retry
    pub initial_delay: Duration,
    /// Maximum delay between retries
    pub max_delay: Duration,
    /// Multiplier for exponential backoff
    pub backoff_multiplier: f64,
    /// Add jitter to prevent thundering herd
    pub jitter: bool,
}

impl Default for RetryConfig {
    fn default() -> Self {
        Self {
            max_attempts: 3,
            initial_delay: Duration::from_millis(100),
            max_delay: Duration::from_secs(5),
            backoff_multiplier: 2.0,
            jitter: true,
        }
    }
}

/// Execute an async operation with retry logic
pub async fn with_retry<F, Fut, T, E>(
    config: &RetryConfig,
    operation_name: &str,
    mut operation: F,
) -> Result<T, E>
where
    F: FnMut() -> Fut,
    Fut: std::future::Future<Output = Result<T, E>>,
    E: std::fmt::Display + IsRetryable,
{
    let mut attempts = 0;
    let mut delay = config.initial_delay;

    loop {
        attempts += 1;

        match operation().await {
            Ok(result) => {
                if attempts > 1 {
                    log::info!(
                        "{} succeeded after {} attempts",
                        operation_name,
                        attempts
                    );
                }
                return Ok(result);
            }
            Err(e) => {
                if !e.is_retryable() || attempts >= config.max_attempts {
                    log::warn!(
                        "{} failed after {} attempts: {}",
                        operation_name,
                        attempts,
                        e
                    );
                    return Err(e);
                }

                // Calculate delay with optional jitter
                let actual_delay = if config.jitter {
                    let jitter_factor = 0.5 + rand::random::<f64>(); // 0.5 to 1.5
                    Duration::from_secs_f64(delay.as_secs_f64() * jitter_factor)
                } else {
                    delay
                };

                log::debug!(
                    "{} attempt {} failed: {}. Retrying in {:?}",
                    operation_name,
                    attempts,
                    e,
                    actual_delay
                );

                sleep(actual_delay).await;

                // Exponential backoff
                delay = Duration::from_secs_f64(
                    (delay.as_secs_f64() * config.backoff_multiplier)
                        .min(config.max_delay.as_secs_f64()),
                );
            }
        }
    }
}

/// Trait for errors that can indicate retryability
pub trait IsRetryable {
    fn is_retryable(&self) -> bool;
}

impl IsRetryable for crate::WsError {
    fn is_retryable(&self) -> bool {
        self.is_retryable()
    }
}
```

**Update**: `backend/crates/pm-ws/src/lib.rs`

Add:
```rust
mod retry;

pub use retry::{RetryConfig, with_retry, IsRetryable};
```

**Verification**: `cargo check -p pm-ws`

---

## Session 10.1 Completion Checklist

After completing all steps:

- [ ] `cargo check -p pm-ws` passes
- [ ] `cargo check --workspace` passes
- [ ] `cargo test -p pm-ws` passes (existing tests)
- [ ] `cargo clippy -p pm-ws` passes

### Files Created (5)
- `pm-ws/src/request_context.rs`
- `pm-ws/src/tracing.rs`
- `pm-ws/src/circuit_breaker.rs`
- `pm-ws/src/retry.rs`

### Files Modified (2)
- `pm-ws/Cargo.toml`
- `pm-ws/src/lib.rs`
- `pm-ws/src/error.rs` (add new variants)

---

## Next Session

**Session 10.2** will implement:
- Handler Context with circuit breaker integration
- DB Operations wrapper
- Error Boundary for panic recovery
- Work Item handlers
- Query handlers
- Dispatcher
