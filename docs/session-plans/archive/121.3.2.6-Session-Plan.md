# Session 121.3.2.6: Bulk Sync Endpoints

**Parent Plan**: [121.3.2-Session-Plan.md](121.3.2-Session-Plan.md)
**Target**: ~30k tokens
**Status**: ✅ **COMPLETE**
**Actual**: ~78k tokens (includes WorkItemRepository refactor/revert + CLI sync commands)
**Prerequisites**:
- `just check-backend && just test-backend && just check-rs-cli` all pass
- **Sessions 121.3.2.1–5 complete** — this session reuses DTOs from those entity modules

---

## Implementation Notes (Actual vs Plan)

### Architecture Improvements
**Plan**: DTOs and sync types in `pm-server`
**Actual**: DTOs and sync types moved to `pm-core` for better separation of concerns
- `backend/crates/pm-core/src/models/*_dto.rs` — All entity DTOs
- `backend/crates/pm-core/src/sync/` — ExportData, ImportResult, EntityImportCounts, helper functions
- `backend/pm-server/src/api/sync/` — HTTP handlers only (export.rs, import.rs)

### WorkItemRepository Special Case
During implementation, discovered that `WorkItemRepository` uses **executor pattern** (not pool pattern) because WebSocket handlers require transactions for atomicity (work item + activity log must be atomic). Attempted refactor to pool pattern broke 27 call sites in `pm-ws`.

**Resolution**: Keep `WorkItemRepository` as the only executor-based repository. All other repositories use pool pattern. The sync handlers call `WorkItemRepository::find_all(pool)` and `WorkItemRepository::create(pool, ...)` directly with the pool as executor.

### CLI Integration (Beyond Plan Scope)
Added full CLI sync commands with proper error handling:
- `pm sync export --output <file>` — exports to JSON file or stdout
- `pm sync import --file <file>` — imports from JSON file
- Added `ClientError::Io` variant with `From<std::io::Error>` for idiomatic error handling

**Testing**: Both commands tested and verified working with idempotent import behavior.

---

## Scope

This session adds two bulk sync endpoints (`GET /api/v1/sync/export` and `POST /api/v1/sync/import`) that export/import ALL entity types in a single HTTP call each. This unblocks Session 121.4 (CLI sync commands).

**Why this is last**: The entity CRUD sessions (121.3.2.1–5) each create their own DTO (`SprintDto`, `DependencyDto`, `SwimLaneDto`, `TimeEntryDto`). This session imports those existing DTOs into `ExportData` — no duplicate `sync_dto.rs` needed.

1. **Repository Gaps** - Add `find_all()` to 6 repositories (Sprint, SwimLane, WorkItem, Comment, Dependency, TimeEntry) for bulk export
2. **Deserialize on DTOs** - Add `Deserialize` derive to all 7 entity DTOs (for import)
3. **ExportData Struct** - Schema with all 7 entity arrays + metadata
4. **Sync Handlers** - Export (gather all entities) and Import (upsert in FK order)
5. **Route Registration** - Wire into router
6. **CLI Client Methods** - `sync_export()` and `sync_import()`

---

## Implementation Order

### Step 1: Add `find_all()` to 6 Repositories

The export handler needs to fetch ALL entities in bulk (not per-project) to avoid N+1 queries. `ProjectRepository` already has `find_all()`. Add it to the other 6:

**1a. SprintRepository** — `backend/crates/pm-db/src/repositories/sprint_repository.rs`

Copy pattern from `find_by_project()`, remove the `WHERE project_id = ?` filter:

```rust
pub async fn find_all(&self) -> DbErrorResult<Vec<Sprint>> {
    // SELECT all sprint columns FROM pm_sprints WHERE deleted_at IS NULL
    // Same row mapping as find_by_project()
}
```

**1b. SwimLaneRepository** — `backend/crates/pm-db/src/repositories/swim_lane_repository.rs`

Copy pattern from `find_by_project()`, remove the `WHERE project_id = ?` filter:

```rust
pub async fn find_all(&self) -> DbErrorResult<Vec<SwimLane>> {
    // SELECT all swim lane columns FROM pm_swim_lanes WHERE deleted_at IS NULL
    // Same row mapping as find_by_project()
}
```

**1c. WorkItemRepository** — `backend/crates/pm-db/src/repositories/work_item_repository.rs`

Copy pattern from `find_by_project()`, remove the `WHERE project_id = ?` filter:

```rust
pub async fn find_all(&self) -> DbErrorResult<Vec<WorkItem>> {
    // SELECT all work item columns FROM pm_work_items WHERE deleted_at IS NULL
    // Same row mapping as find_by_project()
}
```

**1d. CommentRepository** — `backend/crates/pm-db/src/repositories/comment_repository.rs`

Copy pattern from `find_by_work_item()`, remove the `WHERE work_item_id = ?` filter:

```rust
pub async fn find_all(&self) -> DbErrorResult<Vec<Comment>> {
    // SELECT all comment columns FROM pm_comments WHERE deleted_at IS NULL
    // Same row mapping as find_by_work_item()
}
```

**1e. DependencyRepository** — `backend/crates/pm-db/src/repositories/dependency_repository.rs`

Note: `detect_cycle()` was already added to this file in 121.3.2.3. This step only adds `find_all()`.

Copy pattern from `find_blocking()` (line 112), remove the `WHERE blocked_item_id = ?` filter:

```rust
pub async fn find_all(&self) -> DbErrorResult<Vec<Dependency>> {
    // SELECT all dependency columns FROM pm_dependencies WHERE deleted_at IS NULL
    // Same row mapping as find_blocking()
}
```

**1f. TimeEntryRepository** — `backend/crates/pm-db/src/repositories/time_entry_repository.rs`

Copy pattern from `find_by_work_item()` (line 119), remove the `WHERE work_item_id = ?` filter:

```rust
pub async fn find_all(&self) -> DbErrorResult<Vec<TimeEntry>> {
    // SELECT all time entry columns FROM pm_time_entries WHERE deleted_at IS NULL
    // Same row mapping as find_by_work_item()
}
```

**Verification**: `just check-rs-db`

---

### Step 2: Add Deserialize to All Entity DTOs

The import handler needs to deserialize incoming DTOs. Add `Deserialize` derive to all 7 entity DTOs:

| File | Change |
|------|--------|
| `backend/pm-server/src/api/projects/project_dto.rs` | `#[derive(Debug, Serialize)]` → `#[derive(Debug, Serialize, Deserialize)]` |
| `backend/pm-server/src/api/work_items/work_item_dto.rs` | Same |
| `backend/pm-server/src/api/comments/comment_dto.rs` | Same |
| `backend/pm-server/src/api/sprints/sprint_dto.rs` | Same (created in 121.3.2.2) |
| `backend/pm-server/src/api/dependencies/dependency_dto.rs` | Same (created in 121.3.2.3) |
| `backend/pm-server/src/api/swim_lanes/swim_lane_dto.rs` | Same (created in 121.3.2.4) |
| `backend/pm-server/src/api/time_entries/time_entry_dto.rs` | Same (created in 121.3.2.5) |

For each file, ensure `use serde::{Serialize, Deserialize};` (or add `Deserialize` to the existing serde import).

**Verification**: `just check-rs-server`

---

### Step 3: Create ExportData Struct

**Create**: `backend/pm-server/src/api/sync/export_data.rs`

Imports DTOs from existing entity modules — no duplication:

```rust
use crate::{
    ProjectDto, WorkItemDto, CommentDto,
    SprintDto, DependencyDto, SwimLaneDto, TimeEntryDto,
};
use serde::{Serialize, Deserialize};

#[derive(Debug, Serialize, Deserialize)]
pub struct ExportData {
    pub schema_version: u32,
    pub exported_at: String,
    pub exported_by: String,
    pub projects: Vec<ProjectDto>,
    pub work_items: Vec<WorkItemDto>,
    pub sprints: Vec<SprintDto>,
    pub comments: Vec<CommentDto>,
    pub swim_lanes: Vec<SwimLaneDto>,
    pub dependencies: Vec<DependencyDto>,
    pub time_entries: Vec<TimeEntryDto>,
}
```

---

### Step 4: Create Sync Handlers

**Create**: `backend/pm-server/src/api/sync/sync_handlers.rs`

**Export handler** (`GET /api/v1/sync/export`):

Bulk-fetch all entities (7 queries total, no N+1):

```rust
pub async fn sync_export(
    State(state): State<AppState>,
) -> ApiResult<Json<ExportData>> {
    let pool = &state.pool;

    // 7 bulk queries — one per entity type
    let projects = ProjectRepository::new(pool.clone()).find_all().await?;
    let sprints = SprintRepository::new(pool.clone()).find_all().await?;
    let swim_lanes = SwimLaneRepository::new(pool.clone()).find_all().await?;
    let work_items = WorkItemRepository::new(pool.clone()).find_all().await?;
    let comments = CommentRepository::new(pool.clone()).find_all().await?;
    let dependencies = DependencyRepository::new(pool.clone()).find_all().await?;
    let time_entries = TimeEntryRepository::new(pool.clone()).find_all().await?;

    // Convert to DTOs using existing From impls
    let data = ExportData {
        schema_version: 1,
        exported_at: Utc::now().to_rfc3339(),
        exported_by: "pm-server".to_string(),
        projects: projects.into_iter().map(ProjectDto::from).collect(),
        sprints: sprints.into_iter().map(SprintDto::from).collect(),
        swim_lanes: swim_lanes.into_iter().map(SwimLaneDto::from).collect(),
        work_items: work_items.into_iter().map(WorkItemDto::from).collect(),
        comments: comments.into_iter().map(CommentDto::from).collect(),
        dependencies: dependencies.into_iter().map(DependencyDto::from).collect(),
        time_entries: time_entries.into_iter().map(TimeEntryDto::from).collect(),
    };

    Ok(Json(data))
}
```

**Import handler** (`POST /api/v1/sync/import`):
- Accept `Json<ExportData>`
- Validate `schema_version == 1` — return `ApiError::Validation` if unsupported
- Within a transaction, upsert in FK order: projects → sprints → swim_lanes → work_items → comments → dependencies → time_entries
- For each entity: look up by ID, insert if new, update if import is newer, skip if local is newer
- **Conflict resolution strategy**: Compare `updated_at` timestamps. For entities without `updated_at` (Dependencies — only have `created_at`), always overwrite if the entity exists (dependencies are immutable link records, so a re-import is equivalent). If timestamps are equal, skip (local wins on tie).

```rust
pub async fn sync_import(
    State(state): State<AppState>,
    Json(data): Json<ExportData>,
) -> ApiResult<Json<ImportResult>> {
    if data.schema_version != 1 {
        return Err(ApiError::Validation {
            message: format!("Unsupported schema version: {}", data.schema_version),
        });
    }

    let pool = &state.pool;
    let mut result = ImportResult::default();

    // Upsert helper pattern (applied to each entity type):
    // match repo.find_by_id(dto.id).await? {
    //     None => { repo.create(&entity).await?; result.X.created += 1; }
    //     Some(existing) if entity.updated_at > existing.updated_at => {
    //         repo.update(&entity).await?; result.X.updated += 1;
    //     }
    //     Some(_) => { result.X.skipped += 1; }  // local is newer
    // }

    // FK order: projects → sprints → work_items → comments → dependencies → time_entries
    // Swim lanes are SKIPPED — they are fixed configuration created by migrations.
    // Each block converts DTOs back to core models, then upserts

    Ok(Json(result))
}
```

Also define `ImportResult` and per-entity counts:
```rust
#[derive(Debug, Default, Serialize)]
pub struct ImportResult {
    pub projects: EntityImportCounts,
    pub sprints: EntityImportCounts,
    pub swim_lanes: EntityImportCounts,
    pub work_items: EntityImportCounts,
    pub comments: EntityImportCounts,
    pub dependencies: EntityImportCounts,
    pub time_entries: EntityImportCounts,
}

#[derive(Debug, Default, Serialize)]
pub struct EntityImportCounts {
    pub created: usize,
    pub updated: usize,
    pub skipped: usize,
}
```

**DTO → Model conversion (TryFrom impls)**:

The import path requires **6 `TryFrom` implementations** (swim lanes are skipped during import). All impls go in `sync_handlers.rs`. All use `type Error = ApiError`.

Helper pattern used by all impls — define once at the top of the file:
```rust
fn parse_uuid(s: &str, field: &str) -> Result<Uuid, ApiError> {
    Uuid::parse_str(s).map_err(|_| ApiError::Validation {
        message: format!("Invalid UUID for {}: {}", field, s),
        field: Some(field.into()),
        location: ErrorLocation::from(Location::caller()),
    })
}

fn parse_timestamp(ts: i64, field: &str) -> Result<DateTime<Utc>, ApiError> {
    DateTime::from_timestamp(ts, 0).ok_or_else(|| ApiError::Validation {
        message: format!("Invalid timestamp for {}: {}", field, ts),
        field: Some(field.into()),
        location: ErrorLocation::from(Location::caller()),
    })
}
```

**1. `TryFrom<ProjectDto> for Project`**
- Uuid fields: `id`, `created_by`, `updated_by`
- DateTime fields: `created_at`, `updated_at`
- Enum: `status` → `ProjectStatus::from_str()` (variants: "active", "archived")
- Direct: `title`, `description` (Option), `key`, `version` (i32), `next_work_item_number` (i32)
- Set `deleted_at: None`

**2. `TryFrom<SprintDto> for Sprint`**
- Uuid fields: `id`, `project_id`, `created_by`, `updated_by`
- DateTime fields: `start_date`, `end_date`, `created_at`, `updated_at`
- Enum: `status` → `SprintStatus::from_str()` (variants: "planned", "active", "completed", "cancelled")
- Direct: `name`, `goal` (Option), `version` (i32)
- Set `deleted_at: None`

**3. `TryFrom<WorkItemDto> for WorkItem`**
- Uuid fields: `id`, `project_id`, `created_by`, `updated_by`
- **Optional** Uuid fields: `parent_id`, `assignee_id`, `sprint_id` — parse only if `Some`, map `None` → `None`
- DateTime fields: `created_at`, `updated_at`
- Enum: `item_type` → `WorkItemType::from_str()` (variants: "epic", "story", "task")
- **Plain strings** (NOT enums): `status`, `priority` — pass through directly
- Direct: `title`, `description` (Option), `position` (i32), `story_points` (Option<i32>), `item_number` (i32), `version` (i32)
- **Note**: `display_key` exists on WorkItemDto but NOT on WorkItem model — skip it during conversion
- Set `deleted_at: None`

**4. `TryFrom<CommentDto> for Comment`**
- Uuid fields: `id`, `work_item_id`, `created_by`, `updated_by`
- DateTime fields: `created_at`, `updated_at`
- Direct: `content`
- Set `deleted_at: None`

**5. `TryFrom<DependencyDto> for Dependency`**
- Uuid fields: `id`, `blocking_item_id`, `blocked_item_id`, `created_by`
- DateTime fields: `created_at` only — **no `updated_at`** (dependencies are immutable)
- Enum: `dependency_type` → `DependencyType::from_str()` (variants: "blocks", "relates_to")
- **No `updated_by`** field
- Set `deleted_at: None`

**6. `TryFrom<TimeEntryDto> for TimeEntry`**
- Uuid fields: `id`, `work_item_id`, `user_id`
- DateTime fields: `started_at`, `created_at`, `updated_at`
- **Optional** DateTime: `ended_at` — parse only if `Some`
- Direct: `duration_seconds` (Option<i32>), `description` (Option)
- **No `created_by`/`updated_by`** fields
- **Note**: `is_running` exists on TimeEntryDto but NOT on TimeEntry model (it's computed via `is_running()` method) — skip it
- Set `deleted_at: None`

All enum types (`ProjectStatus`, `SprintStatus`, `WorkItemType`, `DependencyType`) already have `FromStr` implementations in `pm-core`.

---

### Step 5: Create Module File

**Create**: `backend/pm-server/src/api/sync/mod.rs`

```rust
pub(crate) mod export_data;
#[allow(clippy::module_inception)]
pub(crate) mod sync_handlers;
```

Note: No `sync_dto.rs` — DTOs come from entity modules.

---

### Step 6: Register Routes + Re-exports

**File**: `backend/pm-server/src/api/mod.rs`

Add: `pub(crate) mod sync;`

**File**: `backend/pm-server/src/lib.rs`

Add re-exports for sync types and handlers:
```rust
sync::{
    export_data::ExportData,
    sync_handlers::{sync_export, sync_import, ImportResult},
},
```

**File**: `backend/pm-server/src/routes.rs`

Add to `build_router()`:
```rust
// REST API v1 - Sync
.route("/api/v1/sync/export", get(sync_export))
.route("/api/v1/sync/import", post(sync_import))
```

Update imports at top of `routes.rs` to include `sync_export, sync_import`.

**Verification**: `just check-rs-server`

---

### Step 7: Add CLI Client Methods

**File**: `backend/crates/pm-cli/src/client/client.rs`

Add a new section after the last entity operations:

```rust
// =========================================================================
// Sync Operations
// =========================================================================

/// Export all data from the server
pub async fn sync_export(&self) -> CliClientResult<Value> {
    let req = self.request(Method::GET, "/api/v1/sync/export");
    self.execute(req).await
}

/// Import data to the server
pub async fn sync_import(&self, data: &Value) -> CliClientResult<Value> {
    let req = self
        .request(Method::POST, "/api/v1/sync/import")
        .json(data);
    self.execute(req).await
}
```

**Verification**: `just check-rs-cli`

---

## Completion Checklist

After completing all steps:

- [x] `just check-backend` passes
- [x] `just clippy-backend` passes
- [x] `just test-backend` passes
- [x] `just check-rs-cli` passes

### Files Created (Actual: 10)

**pm-core sync module (4)**:
- `backend/crates/pm-core/src/sync/mod.rs`
- `backend/crates/pm-core/src/sync/export_data.rs`
- `backend/crates/pm-core/src/sync/import_result.rs`
- `backend/crates/pm-core/src/sync/entity_import_counts.rs`
- `backend/crates/pm-core/src/sync/sync_handlers.rs` (helper functions: parse_uuid, parse_timestamp)

**pm-server sync handlers (2)**:
- `backend/pm-server/src/api/sync/mod.rs`
- `backend/pm-server/src/api/sync/export.rs`
- `backend/pm-server/src/api/sync/import.rs`

**pm-cli sync commands (2)**:
- `backend/crates/pm-cli/src/sync_commands.rs`

### Files Modified (Actual: 23)
**Repositories (7)** — add `find_all()`:
- `backend/crates/pm-db/src/repositories/project_repository.rs`
- `backend/crates/pm-db/src/repositories/sprint_repository.rs`
- `backend/crates/pm-db/src/repositories/swim_lane_repository.rs`
- `backend/crates/pm-db/src/repositories/work_item_repository.rs` (executor pattern)
- `backend/crates/pm-db/src/repositories/comment_repository.rs`
- `backend/crates/pm-db/src/repositories/dependency_repository.rs`
- `backend/crates/pm-db/src/repositories/time_entry_repository.rs`

**DTOs (7)** — moved to pm-core, add `Deserialize` and `TryFrom`:
- `backend/crates/pm-core/src/models/project_dto.rs`
- `backend/crates/pm-core/src/models/sprint_dto.rs`
- `backend/crates/pm-core/src/models/swim_lane_dto.rs`
- `backend/crates/pm-core/src/models/work_item_dto.rs`
- `backend/crates/pm-core/src/models/comment_dto.rs`
- `backend/crates/pm-core/src/models/dependency_dto.rs`
- `backend/crates/pm-core/src/models/time_entry_dto.rs`

**pm-core module structure**:
- `backend/crates/pm-core/src/models/mod.rs` — export all DTOs
- `backend/crates/pm-core/src/lib.rs` — re-export sync types

**pm-server integration**:
- `backend/pm-server/src/api/mod.rs` — add `sync` module
- `backend/pm-server/src/lib.rs` — re-export sync handlers
- `backend/pm-server/src/routes.rs` — register 2 routes (export, import)

**pm-cli integration**:
- `backend/crates/pm-cli/src/client/client.rs` — add export_data(), import_data()
- `backend/crates/pm-cli/src/client/error.rs` — add `Io` variant with From<std::io::Error>
- `backend/crates/pm-cli/src/commands.rs` — add Sync command
- `backend/crates/pm-cli/src/main.rs` — wire sync command dispatch, add sync_commands import

---

## Key Learnings

### 1. Repository Pattern Consistency vs. Flexibility
**Issue**: Attempted to refactor `WorkItemRepository` from executor pattern to pool pattern to match other repositories. This broke 27 call sites in `pm-ws` that use transactions.

**Root Cause**: WebSocket handlers require transactions to maintain atomicity between work item operations and activity log writes. Transactions require passing an executor (transaction handle), not a pool.

**Resolution**: Keep `WorkItemRepository` as executor-based. This is a valid architectural decision — not all repositories need the same pattern. Transaction support is more important than pattern consistency.

**Lesson**: Always check ALL call sites before refactoring. Use `rg "RepositoryName::"` to find all usages.

### 2. Idiomatic Rust Error Handling
**Pattern**: `From<T>` trait + `?` operator is the idiomatic way to handle errors in Rust.

**Example**:
```rust
// BAD: Manual conversion
let json = serde_json::to_string(&data)
    .map_err(|e| ClientError::JsonError(e.to_string()))?;

// GOOD: Automatic conversion with From impl
let json = serde_json::to_string(&data)?;
```

**Implementation**: Added `ClientError::Io` variant with proper error handling:
- Struct variant with `message`, `location`, and `source` fields
- `from_io()` helper with `#[track_caller]` for location tracking
- `From<std::io::Error>` impl for automatic `?` operator support

This matches the existing patterns for `Http` and `Json` error variants.

### 3. Architecture: Core Types in Core Crate
**Decision**: Moved DTOs and sync types from `pm-server` to `pm-core` during implementation.

**Rationale**:
- DTOs are data structures, not HTTP handlers — belong in core
- Sync types (ExportData, ImportResult) are domain models — belong in core
- Only HTTP handlers (export.rs, import.rs) remain in pm-server
- Cleaner separation: core = types/logic, pm-server = HTTP layer

**Benefit**: Other crates (future CLI tools, desktop app) can import DTOs from pm-core without depending on pm-server.

---

## Testing Results

**Export Test**:
```bash
./pm sync export --output data.json --pretty
```
- Successfully exports all 7 entity types (projects, sprints, work_items, comments, dependencies, swim_lanes, time_entries)
- Clean JSON output with schema_version and metadata

**Import Test**:
```bash
./pm sync import --file data.json --pretty
```
- Idempotent behavior: skips existing items with same/newer updated_at
- Conflict resolution: creates if new, updates if import is newer, skips if local is newer
- Returns detailed counts per entity type (created, updated, skipped)

**Example Output**:
- 1 project skipped (already exists)
- 2 work items skipped (already exist)
- Demonstrates proper conflict resolution

---

## Next Session

**Session 121.4** (CLI data sync workflow) is now unblocked. The bulk sync endpoints (`GET /api/v1/sync/export`, `POST /api/v1/sync/import`) and CLI commands (`pm sync export`, `pm sync import`) are complete and tested.
