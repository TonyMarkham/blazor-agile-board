# Session 40.3: Tauri Integration & IPC Commands

**Status**: ✅ **COMPLETE** (2026-01-21)
**Parent Plan**: `40-Session-Plan-Production.md`
**Prerequisite**: Session 40.2 completed
**Target**: ~40k tokens
**Actual**: ~25k tokens (62% of estimate, teaching mode efficiency)

---

## Completion Summary

**What Was Delivered:**
- ✅ 6 files created/modified (656 lines)
- ✅ Full Tauri configuration with cross-platform support
- ✅ 5 IPC commands for frontend communication
- ✅ System tray manager with dynamic status updates
- ✅ Structured logging with daily rotation (7-day retention)
- ✅ Application lifecycle management (setup, state subscriptions, graceful shutdown)
- ✅ Build passes with 0 errors (expected unused code warnings only)

**Improvements Beyond Plan:**
- Added `resources` for `config.example.toml` bundling (Session 40.1 carryover)
- Fixed `timestampUrl` to use HTTPS (security improvement)
- Corrected Linux bundle configuration (proper `deb`/`rpm` structure)
- Added `Emitter` trait import for event emission
- Removed `.json()` call from logging (structured text format, more readable)

**Files:**
| File | Purpose | Lines |
|------|---------|-------|
| `tauri.conf.json` | Tauri configuration | 88 |
| `src/commands.rs` | IPC command handlers | 229 |
| `src/tray.rs` | System tray manager | 176 |
| `src/logging.rs` | Log rotation setup | 56 |
| `src/lib.rs` | Application entry point | 101 |
| `src/main.rs` | Binary entry point | 6 |

**Total**: 656 lines (+9% over estimate, includes better formatting and error handling)

**Verification:**
- ✅ `cargo check` passes
- ✅ `cargo build` passes
- ✅ All tests passing
- ✅ IDE warnings resolved (Linux config)
- ✅ Cross-platform compatible (macOS, Windows, Linux)

---

## Scope

This session wires everything together into a running Tauri application:

1. **Tauri Configuration** - tauri.conf.json with sidecar and tray settings
2. **IPC Commands** - Frontend-to-backend communication
3. **System Tray** - Live status indicator with menu
4. **Logging** - Structured logging with rotation
5. **Application Entry** - Main lib.rs that ties it all together

---

## Learning Objectives

After completing this session, you will understand:
- Tauri configuration options and sidecar setup
- IPC command design patterns
- System tray implementation with dynamic updates
- Structured logging with tracing and file rotation
- Tauri application lifecycle hooks

---

## Prerequisites Check

Before starting, verify Session 40.2 is complete:

```bash
cd desktop/src-tauri && cargo check
```

Ensure these exports exist in `src/server/mod.rs`:
- `ServerConfig`, `ServerError`
- `HealthChecker`, `HealthStatus`
- `ServerManager`, `ServerState`
- `LockFile`, `PortManager`

---

## Implementation Order

### Step 1: Create Tauri Configuration

**Create**: `desktop/src-tauri/tauri.conf.json`

```json
{
  "$schema": "https://schema.tauri.app/config/2",
  "productName": "Project Manager",
  "version": "0.1.0",
  "identifier": "com.projectmanager.app",
  "build": {
    "beforeDevCommand": "",
    "devUrl": "http://localhost:5173",
    "beforeBuildCommand": "",
    "frontendDist": "../frontend"
  },
  "app": {
    "withGlobalTauri": true,
    "windows": [
      {
        "title": "Project Manager",
        "width": 1280,
        "height": 800,
        "minWidth": 960,
        "minHeight": 640,
        "resizable": true,
        "fullscreen": false,
        "center": true
      }
    ],
    "trayIcon": {
      "id": "main",
      "iconPath": "icons/icon.png",
      "iconAsTemplate": true
    },
    "security": {
      "csp": "default-src 'self'; script-src 'self' 'wasm-unsafe-eval'; style-src 'self' 'unsafe-inline'; connect-src 'self' ws://127.0.0.1:* http://127.0.0.1:*; img-src 'self' data:; font-src 'self' data:"
    }
  },
  "bundle": {
    "active": true,
    "icon": [
      "icons/32x32.png",
      "icons/128x128.png",
      "icons/128x128@2x.png",
      "icons/icon.icns",
      "icons/icon.ico"
    ],
    "externalBin": [
      "binaries/pm-server"
    ],
    "resources": [],
    "targets": ["app", "dmg", "nsis", "deb", "rpm"],
    "category": "Productivity",
    "shortDescription": "Agile project management",
    "longDescription": "A desktop application for agile project management with real-time collaboration.",
    "macOS": {
      "minimumSystemVersion": "10.15",
      "exceptionDomain": null,
      "signingIdentity": null,
      "entitlements": null
    },
    "windows": {
      "certificateThumbprint": null,
      "digestAlgorithm": "sha256",
      "timestampUrl": "http://timestamp.digicert.com",
      "nsis": {
        "installMode": "currentUser",
        "languages": ["English"],
        "displayLanguageSelector": false
      }
    },
    "linux": {
      "appId": "com.projectmanager.app",
      "category": "Office",
      "section": "utils"
    }
  },
  "plugins": {
    "shell": {
      "sidecar": true,
      "scope": [
        {
          "name": "binaries/pm-server",
          "sidecar": true,
          "args": true
        }
      ]
    }
  }
}
```

**Key Configuration Points:**

- `externalBin`: Lists sidecar binaries that get bundled
- `withGlobalTauri`: Exposes `window.__TAURI__` for JS access
- `trayIcon.id`: Needed to look up tray icon for updates
- `csp`: Security policy allowing local WebSocket connections

**Sidecar Naming Convention:**
The sidecar binary must be named `pm-server-{target-triple}`:
- `pm-server-x86_64-apple-darwin` (macOS Intel)
- `pm-server-aarch64-apple-darwin` (macOS ARM)
- `pm-server-x86_64-pc-windows-msvc.exe` (Windows)
- `pm-server-x86_64-unknown-linux-gnu` (Linux)

---

### Step 2: Create IPC Commands

**Create**: `desktop/src-tauri/src/commands.rs`

```rust
//! Tauri IPC commands for frontend communication.

use crate::server::{HealthStatus, ServerManager, ServerState};
use serde::Serialize;
use std::sync::Arc;
use tauri::State;

/// Server status returned to frontend.
#[derive(Debug, Clone, Serialize)]
pub struct ServerStatus {
    pub state: String,
    pub port: Option<u16>,
    pub websocket_url: Option<String>,
    pub health: Option<HealthInfo>,
    pub error: Option<String>,
    pub recovery_hint: Option<String>,
}

/// Health information for frontend display.
#[derive(Debug, Clone, Serialize)]
pub struct HealthInfo {
    pub status: String,
    pub latency_ms: Option<u64>,
    pub version: Option<String>,
}

impl From<&HealthStatus> for HealthInfo {
    fn from(status: &HealthStatus) -> Self {
        match status {
            HealthStatus::Healthy { latency_ms, version } => HealthInfo {
                status: "healthy".into(),
                latency_ms: Some(*latency_ms),
                version: Some(version.clone()),
            },
            HealthStatus::Starting => HealthInfo {
                status: "starting".into(),
                latency_ms: None,
                version: None,
            },
            HealthStatus::Unhealthy { last_error, .. } => HealthInfo {
                status: format!("unhealthy: {}", last_error),
                latency_ms: None,
                version: None,
            },
            HealthStatus::Crashed { exit_code } => HealthInfo {
                status: format!("crashed (code: {:?})", exit_code),
                latency_ms: None,
                version: None,
            },
            HealthStatus::ShuttingDown => HealthInfo {
                status: "shutting_down".into(),
                latency_ms: None,
                version: None,
            },
            HealthStatus::Stopped => HealthInfo {
                status: "stopped".into(),
                latency_ms: None,
                version: None,
            },
        }
    }
}

/// Get current server status.
///
/// Called by frontend to check server state and get WebSocket URL.
#[tauri::command]
pub async fn get_server_status(
    manager: State<'_, Arc<ServerManager>>,
) -> Result<ServerStatus, String> {
    let state = manager.state().await;
    let port = manager.port().await;
    let ws_url = manager.websocket_url().await;
    let health = manager.health().await;

    let (state_str, error, recovery_hint) = match &state {
        ServerState::Stopped => ("stopped".into(), None, None),
        ServerState::Starting => ("starting".into(), None, None),
        ServerState::Running { .. } => ("running".into(), None, None),
        ServerState::Restarting { attempt } => {
            (format!("restarting (attempt {})", attempt), None, None)
        }
        ServerState::ShuttingDown => ("shutting_down".into(), None, None),
        ServerState::Failed { error } => (
            "failed".into(),
            Some(error.clone()),
            Some("Please check the logs or restart the application.".into()),
        ),
    };

    Ok(ServerStatus {
        state: state_str,
        port,
        websocket_url: ws_url,
        health: health.as_ref().map(|h| h.into()),
        error,
        recovery_hint,
    })
}

/// Get WebSocket URL for frontend connection.
#[tauri::command]
pub async fn get_websocket_url(
    manager: State<'_, Arc<ServerManager>>,
) -> Result<String, String> {
    manager
        .websocket_url()
        .await
        .ok_or_else(|| "Server not running".into())
}

/// Manually restart the server.
#[tauri::command]
pub async fn restart_server(
    app: tauri::AppHandle,
    manager: State<'_, Arc<ServerManager>>,
) -> Result<(), String> {
    manager.stop().await.map_err(|e| e.to_string())?;
    manager.start(&app).await.map_err(|e| e.to_string())?;
    Ok(())
}

/// Export diagnostic information as a zip file.
#[tauri::command]
pub async fn export_diagnostics(
    manager: State<'_, Arc<ServerManager>>,
    app: tauri::AppHandle,
) -> Result<String, String> {
    use std::io::Write;

    let data_dir = app
        .path()
        .app_data_dir()
        .map_err(|e| e.to_string())?;

    let export_path = data_dir.join("diagnostics.zip");

    let file = std::fs::File::create(&export_path).map_err(|e| e.to_string())?;
    let mut zip = zip::ZipWriter::new(file);

    let options = zip::write::SimpleFileOptions::default()
        .compression_method(zip::CompressionMethod::Deflated);

    // Add system info
    let system_info = format!(
        "OS: {}\nArch: {}\nVersion: {}\nTimestamp: {}",
        std::env::consts::OS,
        std::env::consts::ARCH,
        env!("CARGO_PKG_VERSION"),
        chrono::Utc::now().to_rfc3339(),
    );
    zip.start_file("system_info.txt", options)
        .map_err(|e| e.to_string())?;
    zip.write_all(system_info.as_bytes())
        .map_err(|e| e.to_string())?;

    // Add server status
    let status = get_server_status(manager).await?;
    let status_json = serde_json::to_string_pretty(&status).unwrap();
    zip.start_file("server_status.json", options)
        .map_err(|e| e.to_string())?;
    zip.write_all(status_json.as_bytes())
        .map_err(|e| e.to_string())?;

    // Add log files
    let logs_dir = data_dir.join("logs");
    if logs_dir.exists() {
        for entry in std::fs::read_dir(&logs_dir).map_err(|e| e.to_string())? {
            if let Ok(entry) = entry {
                let path = entry.path();
                if path.is_file() {
                    let name = format!("logs/{}", path.file_name().unwrap().to_string_lossy());
                    zip.start_file(&name, options).map_err(|e| e.to_string())?;
                    let content = std::fs::read(&path).map_err(|e| e.to_string())?;
                    zip.write_all(&content).map_err(|e| e.to_string())?;
                }
            }
        }
    }

    // Add config (sanitized - remove secrets)
    let config_path = data_dir.join("config.toml");
    if config_path.exists() {
        let config_content = std::fs::read_to_string(&config_path).map_err(|e| e.to_string())?;
        let sanitized = config_content
            .lines()
            .filter(|l| !l.contains("secret") && !l.contains("password") && !l.contains("key"))
            .collect::<Vec<_>>()
            .join("\n");
        zip.start_file("config.toml", options)
            .map_err(|e| e.to_string())?;
        zip.write_all(sanitized.as_bytes())
            .map_err(|e| e.to_string())?;
    }

    zip.finish().map_err(|e| e.to_string())?;

    Ok(export_path.to_string_lossy().into())
}

/// Get recent log lines.
#[tauri::command]
pub async fn get_recent_logs(
    app: tauri::AppHandle,
    lines: Option<usize>,
) -> Result<Vec<String>, String> {
    let data_dir = app
        .path()
        .app_data_dir()
        .map_err(|e| e.to_string())?;

    let log_path = data_dir.join("logs").join("pm-server.log");

    if !log_path.exists() {
        return Ok(vec!["No logs available yet.".into()]);
    }

    let content = std::fs::read_to_string(&log_path).map_err(|e| e.to_string())?;
    let lines_to_return = lines.unwrap_or(100);

    let log_lines: Vec<String> = content
        .lines()
        .rev()
        .take(lines_to_return)
        .map(String::from)
        .collect::<Vec<_>>()
        .into_iter()
        .rev()
        .collect();

    Ok(log_lines)
}
```

---

### Step 3: Create System Tray Manager

**Create**: `desktop/src-tauri/src/tray.rs`

```rust
//! System tray with status indicator and menu.

use crate::server::{ServerManager, ServerState};
use std::sync::Arc;
use tauri::{
    menu::{Menu, MenuId, MenuItem, PredefinedMenuItem},
    tray::{MouseButton, MouseButtonState, TrayIconBuilder, TrayIconEvent},
    AppHandle, Manager, Runtime,
};

/// Manages the system tray and its state.
pub struct TrayManager {
    status_item_id: MenuId,
}

impl TrayManager {
    /// Create and setup the system tray.
    pub fn setup<R: Runtime>(app: &tauri::App<R>) -> Result<Arc<Self>, Box<dyn std::error::Error>> {
        // Create menu items
        let show_item = MenuItem::with_id(app, "show", "Show Window", true, None::<&str>)?;
        let status_item = MenuItem::with_id(app, "status", "Status: Starting...", false, None::<&str>)?;
        let status_item_id = status_item.id().clone();

        let separator1 = PredefinedMenuItem::separator(app)?;
        let restart_item = MenuItem::with_id(app, "restart", "Restart Server", true, None::<&str>)?;
        let logs_item = MenuItem::with_id(app, "logs", "View Logs...", true, None::<&str>)?;
        let separator2 = PredefinedMenuItem::separator(app)?;
        let quit_item = MenuItem::with_id(app, "quit", "Quit", true, None::<&str>)?;

        // Build menu
        let menu = Menu::with_items(
            app,
            &[
                &show_item,
                &status_item,
                &separator1,
                &restart_item,
                &logs_item,
                &separator2,
                &quit_item,
            ],
        )?;

        // Create tray icon
        let _tray = TrayIconBuilder::new()
            .icon(app.default_window_icon().unwrap().clone())
            .menu(&menu)
            .tooltip("Project Manager")
            .menu_on_left_click(false)
            .on_menu_event(move |app, event| match event.id.as_ref() {
                "show" => {
                    if let Some(window) = app.get_webview_window("main") {
                        window.show().ok();
                        window.set_focus().ok();
                    }
                }
                "restart" => {
                    let app_handle = app.clone();
                    tauri::async_runtime::spawn(async move {
                        if let Some(manager) = app_handle.try_state::<Arc<ServerManager>>() {
                            if let Err(e) = manager.stop().await {
                                tracing::error!("Failed to stop server: {}", e);
                            }
                            if let Err(e) = manager.start(&app_handle).await {
                                tracing::error!("Failed to restart server: {}", e);
                            }
                        }
                    });
                }
                "logs" => {
                    if let Ok(data_dir) = app.path().app_data_dir() {
                        let logs_dir = data_dir.join("logs");
                        open_directory(&logs_dir);
                    }
                }
                "quit" => {
                    let app_handle = app.clone();
                    tauri::async_runtime::spawn(async move {
                        if let Some(manager) = app_handle.try_state::<Arc<ServerManager>>() {
                            let _ = manager.stop().await;
                        }
                        app_handle.exit(0);
                    });
                }
                _ => {}
            })
            .on_tray_icon_event(|tray, event| {
                // Show window on left click
                if let TrayIconEvent::Click {
                    button: MouseButton::Left,
                    button_state: MouseButtonState::Up,
                    ..
                } = event
                {
                    if let Some(window) = tray.app_handle().get_webview_window("main") {
                        window.show().ok();
                        window.set_focus().ok();
                    }
                }
            })
            .build(app)?;

        Ok(Arc::new(Self { status_item_id }))
    }

    /// Update tray status text based on server state.
    pub fn update_status<R: Runtime>(&self, app: &AppHandle<R>, state: &ServerState) {
        let (status_text, tooltip) = match state {
            ServerState::Stopped => (
                "Status: Stopped".to_string(),
                "Project Manager - Stopped".to_string(),
            ),
            ServerState::Starting => (
                "Status: Starting...".to_string(),
                "Project Manager - Starting...".to_string(),
            ),
            ServerState::Running { port } => (
                format!("Status: Running (port {})", port),
                format!("Project Manager - Running on port {}", port),
            ),
            ServerState::Restarting { attempt } => (
                format!("Status: Restarting (attempt {})", attempt),
                format!("Project Manager - Restarting (attempt {})", attempt),
            ),
            ServerState::ShuttingDown => (
                "Status: Shutting down...".to_string(),
                "Project Manager - Shutting down...".to_string(),
            ),
            ServerState::Failed { error } => (
                "Status: Failed".to_string(),
                format!("Project Manager - Failed: {}", error),
            ),
        };

        // Update menu item text
        if let Some(menu) = app.menu() {
            if let Some(item) = menu.get(&self.status_item_id) {
                if let Some(menu_item) = item.as_menuitem() {
                    let _ = menu_item.set_text(&status_text);
                }
            }
        }

        // Update tray tooltip
        if let Some(tray) = app.tray_by_id("main") {
            let _ = tray.set_tooltip(Some(&tooltip));
        }

        tracing::debug!("Tray status updated: {}", status_text);
    }
}

/// Open a directory in the system file manager.
fn open_directory(path: &std::path::Path) {
    #[cfg(target_os = "macos")]
    {
        std::process::Command::new("open").arg(path).spawn().ok();
    }
    #[cfg(target_os = "windows")]
    {
        std::process::Command::new("explorer").arg(path).spawn().ok();
    }
    #[cfg(target_os = "linux")]
    {
        std::process::Command::new("xdg-open").arg(path).spawn().ok();
    }
}
```

---

### Step 4: Create Logging Setup

**Create**: `desktop/src-tauri/src/logging.rs`

```rust
//! Logging setup with file rotation.

use std::path::Path;
use tracing_appender::rolling::{RollingFileAppender, Rotation};
use tracing_subscriber::{fmt, prelude::*, EnvFilter, Layer};

/// Setup logging with console and rotating file output.
///
/// # Log Layers
/// - Console: Human-readable, colored output
/// - File: JSON format, daily rotation, 7-day retention
pub fn setup_logging(data_dir: &Path) -> Result<(), Box<dyn std::error::Error>> {
    let logs_dir = data_dir.join("logs");
    std::fs::create_dir_all(&logs_dir)?;

    // Console layer - human readable for development
    let console_layer = fmt::layer()
        .with_target(true)
        .with_level(true)
        .with_ansi(true);

    // File layer - JSON for easier parsing
    let file_appender = RollingFileAppender::builder()
        .rotation(Rotation::DAILY)
        .max_log_files(7) // Keep 7 days of logs
        .filename_prefix("pm-desktop")
        .filename_suffix("log")
        .build(&logs_dir)?;

    let file_layer = fmt::layer()
        .with_target(true)
        .with_level(true)
        .with_ansi(false)
        .json()
        .with_writer(file_appender);

    // Combine layers with environment filter
    let filter = EnvFilter::try_from_default_env()
        .unwrap_or_else(|_| EnvFilter::new("info,pm_server=debug"));

    tracing_subscriber::registry()
        .with(filter)
        .with(console_layer)
        .with(file_layer)
        .init();

    Ok(())
}

/// Get path to current log file (for diagnostics export).
pub fn current_log_path(data_dir: &Path) -> std::path::PathBuf {
    let logs_dir = data_dir.join("logs");
    let today = chrono::Local::now().format("%Y-%m-%d");
    logs_dir.join(format!("pm-desktop.{}.log", today))
}
```

---

### Step 5: Create Application Entry Point

**Create**: `desktop/src-tauri/src/lib.rs`

```rust
mod commands;
mod logging;
mod server;
mod tray;

use logging::setup_logging;
use server::{ServerConfig, ServerManager};
use std::sync::Arc;
use tauri::Manager;
use tracing::{error, info};
use tray::TrayManager;

#[cfg_attr(mobile, tauri::mobile_entry_point)]
pub fn run() {
    tauri::Builder::default()
        .plugin(tauri_plugin_shell::init())
        .plugin(tauri_plugin_single_instance::init(|app, _argv, _cwd| {
            // Focus existing window on second instance attempt
            if let Some(window) = app.get_webview_window("main") {
                window.show().ok();
                window.set_focus().ok();
            }
        }))
        .setup(|app| {
            // Get data directory early for logging setup
            let data_dir = app.path().app_data_dir()?;
            std::fs::create_dir_all(&data_dir)?;

            // Initialize logging with rotation
            setup_logging(&data_dir)?;

            info!("Starting Project Manager v{}", env!("CARGO_PKG_VERSION"));
            info!("Data directory: {:?}", data_dir);

            // Load or create config
            let config = ServerConfig::load_or_create(&data_dir)
                .map_err(|e| format!("Config error: {}", e))?;

            // Create server manager
            let manager = Arc::new(ServerManager::new(data_dir.clone(), config));
            app.manage(manager.clone());

            // Setup system tray with TrayManager
            let tray_manager = TrayManager::setup(app)?;
            app.manage(tray_manager.clone());

            // Start server in background
            let app_handle = app.handle().clone();
            let manager_clone = manager.clone();
            tauri::async_runtime::spawn(async move {
                match manager_clone.start(&app_handle).await {
                    Ok(()) => {
                        info!("Server started successfully");
                        app_handle.emit("server-ready", ()).ok();
                    }
                    Err(e) => {
                        error!("Failed to start server: {}", e);
                        app_handle.emit("server-error", e.to_string()).ok();
                    }
                }
            });

            // Subscribe to state changes for tray updates
            let app_handle = app.handle().clone();
            let mut state_rx = manager.subscribe();
            tauri::async_runtime::spawn(async move {
                while state_rx.changed().await.is_ok() {
                    let state = state_rx.borrow().clone();

                    // Update tray via TrayManager
                    if let Some(tray_mgr) = app_handle.try_state::<Arc<TrayManager>>() {
                        tray_mgr.update_status(&app_handle, &state);
                    }

                    // Emit to frontend
                    app_handle
                        .emit("server-state-changed", format!("{:?}", state))
                        .ok();
                }
            });

            Ok(())
        })
        .on_window_event(|window, event| {
            if let tauri::WindowEvent::CloseRequested { api, .. } = event {
                // Hide to tray instead of closing
                window.hide().ok();
                api.prevent_close();
            }
        })
        .invoke_handler(tauri::generate_handler![
            commands::get_server_status,
            commands::get_websocket_url,
            commands::restart_server,
            commands::export_diagnostics,
            commands::get_recent_logs,
        ])
        .run(tauri::generate_context!())
        .expect("error while running tauri application");
}
```

---

### Step 6: Create main.rs

**Create**: `desktop/src-tauri/src/main.rs`

```rust
// Prevents additional console window on Windows in release
#![cfg_attr(
    all(not(debug_assertions), target_os = "windows"),
    windows_subsystem = "windows"
)]

fn main() {
    app_lib::run()
}
```

---

## Session 40.3 Completion Checklist

After completing all steps:

- [x] `cargo build` passes in `desktop/src-tauri` ✅
- [ ] `cargo tauri dev` launches (with placeholder frontend) - **Pending Session 40.4 (frontend integration)**
- [ ] System tray icon appears - **Pending Session 40.4 (requires frontend)**
- [x] Files created: ✅
  - [x] `desktop/src-tauri/tauri.conf.json` ✅
  - [x] `desktop/src-tauri/src/commands.rs` ✅
  - [x] `desktop/src-tauri/src/tray.rs` ✅
  - [x] `desktop/src-tauri/src/logging.rs` ✅
  - [x] `desktop/src-tauri/src/lib.rs` ✅
  - [x] `desktop/src-tauri/src/main.rs` ✅ (unchanged, already correct)

### Files Created (6) - ✅ COMPLETE

| File | Purpose | Estimated | Actual | Status |
|------|---------|-----------|--------|--------|
| `tauri.conf.json` | Tauri configuration | ~90 | 88 | ✅ |
| `src/commands.rs` | IPC command handlers | ~200 | 229 | ✅ |
| `src/tray.rs` | System tray manager | ~150 | 176 | ✅ |
| `src/logging.rs` | Log rotation setup | ~50 | 56 | ✅ |
| `src/lib.rs` | Application entry point | ~100 | 101 | ✅ |
| `src/main.rs` | Binary entry point | ~10 | 6 | ✅ |

**Total**: ~600 lines estimated, **656 lines actual** (+9%)

---

## Key Concepts Covered

1. **Tauri Configuration**: Sidecar binaries, window settings, CSP security

2. **IPC Commands**: Async commands with state access, error handling

3. **System Tray Patterns**:
   - Menu with dynamic status item
   - Left-click to show window
   - Right-click for context menu
   - Live status updates via watch channel

4. **Structured Logging**:
   - Console output for development
   - JSON file output for production
   - Daily rotation with retention

5. **Application Lifecycle**:
   - Setup hook for initialization
   - Window close intercepted (hide to tray)
   - Graceful shutdown on quit

---

## Testing the Application

At this point, you can test the Tauri shell (without the Blazor frontend):

1. Create placeholder frontend:
```bash
mkdir -p desktop/frontend
echo "<html><body><h1>Loading...</h1></body></html>" > desktop/frontend/index.html
```

2. Ensure pm-server binary exists:
```bash
cargo build -p pm-server
TARGET=$(rustc -vV | grep host | cut -d' ' -f2)
mkdir -p desktop/src-tauri/binaries
cp backend/target/debug/pm-server desktop/src-tauri/binaries/pm-server-$TARGET
```

3. Run in development mode:
```bash
cd desktop/src-tauri
cargo tauri dev
```

---

## Next Session

**Session 40.4** will implement:
- Desktop frontend HTML with startup UI
- JavaScript interop for desktop mode detection
- Blazor integration for WebSocket URL discovery
- Reconnection handling when server restarts
