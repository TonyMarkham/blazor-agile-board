# Session 70.1: Backend Foundation - Activity Log & LLM Context

**Parent Plan**: `70-Session-Plan.md`
**Target**: ~40-45k tokens
**Prerequisites**: Session 60 complete, `just check` passes
**Status**: ✅ Complete
**Verified**: `just check-rs-ws`, `just check-rs-db`, `just test-rs-ws`, `just test-rs-db`

---

## Scope

This session implements backend infrastructure for activity history and LLM integration:

1. **Proto Messages** (Part 1) - ALL message definitions first
2. **Database Migrations** (Part 2) - LLM context seed data
3. **Models** (Part 3) - Domain models for LLM context
4. **Repositories** (Part 4) - Activity log pagination & LLM context queries
5. **Handlers** (Part 5) - Activity log & LLM context query endpoints
6. **Response Builders** (Part 6) - Proto response construction
7. **Dispatcher Integration** (Part 7) - Wire handlers to message routing
8. **Tests** (Part 8) - Repository and handler tests

---

## Prerequisites Check

Before starting, verify:

```bash
just check          # All code compiles
just test-backend   # All existing tests pass
```

Ensure these exist:
- `pm_activity_log` table in database
- `pm_llm_context` table in database (empty is OK)
- Activity logging in work_item/sprint/comment handlers

---

## Implementation Order

### Part 1: Proto Messages (ALL MESSAGES FIRST)

#### Step 1.1: Add ALL Activity Log and LLM Context Messages

**File**: `proto/messages.proto`

Add at fields 140-145 (after Session 60's last field):

```protobuf
// ========================================
// Activity Log Messages (fields 140-142)
// ========================================

message GetActivityLogRequest {
  string entity_type = 1;  // "work_item", "sprint", "comment", "time_entry", "dependency", "project"
  string entity_id = 2;
  int32 limit = 3;         // Default 50, max 100, validated
  int32 offset = 4;        // For pagination, default 0
}

message ActivityLogEntry {
  string id = 1;
  string entity_type = 2;
  string entity_id = 3;
  string action = 4;       // "created", "updated", "deleted"
  optional string field_name = 5;
  optional string old_value = 6;
  optional string new_value = 7;
  string user_id = 8;
  int64 timestamp = 9;
  optional string comment = 10;
}

message ActivityLogList {
  repeated ActivityLogEntry entries = 1;
  int32 total_count = 2;   // For pagination UI
  bool has_more = 3;       // Quick check for "load more"
}

// Real-time activity broadcast (sent to subscribed clients)
message ActivityLogCreated {
  ActivityLogEntry entry = 1;
}

// ========================================
// LLM Context Messages (fields 143-145)
// ========================================

message GetLlmContextRequest {
  optional string category = 1;      // Filter by category
  optional string context_type = 2;  // Filter by type
  optional int32 min_priority = 3;   // Filter by minimum priority
}

message LlmContextEntry {
  string id = 1;
  string context_type = 2;
  string category = 3;
  string title = 4;
  string content = 5;
  optional string example_sql = 6;
  optional string example_description = 7;
  int32 priority = 8;
}

message LlmContextList {
  repeated LlmContextEntry entries = 1;
}
```

**Also add to the Payload oneof** (around line 50):

```protobuf
oneof payload {
  // ... existing messages ...

  // Activity Log (Session 70)
  GetActivityLogRequest get_activity_log_request = 140;
  ActivityLogList activity_log_list = 141;
  ActivityLogCreated activity_log_created = 142;

  // LLM Context (Session 70)
  GetLlmContextRequest get_llm_context_request = 143;
  LlmContextList llm_context_list = 144;
}
```

**Rebuild proto:**
```bash
just build-rs-proto
```

**Verification**: `cargo check -p pm-proto`

---

### Part 2: Database Migrations (ALL MIGRATIONS NEXT)

#### Step 2.1: Add LLM Context Seed Data

**Create**: `backend/crates/pm-db/migrations/20260127000001_seed_llm_context.sql`

```sql
-- Seed LLM context with self-documenting database information
-- This migration is idempotent (uses INSERT OR IGNORE)

-- Schema Documentation (Priority 100) - 10 entries
INSERT OR IGNORE INTO pm_llm_context (id, context_type, category, title, content, priority, created_at, updated_at)
VALUES
('11111111-1111-1111-1111-000000000001', 'schema_doc', 'work_items', 'Work Item Hierarchy',
 'Single-table polymorphic design with item_type (project/epic/story/task). Uses parent_id for hierarchy and project_id for filtering. Position field for drag-and-drop ordering.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000002', 'schema_doc', 'sprints', 'Sprint Lifecycle',
 'Status transitions: planned → active → completed/cancelled. Version field for optimistic locking. Start/end dates and velocity tracking.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000003', 'schema_doc', 'comments', 'Comment Threading',
 'work_item_id FK for parent work item. author_id for ownership checks. parent_id for threaded replies (optional).',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000004', 'schema_doc', 'time_entries', 'Time Entry Structure',
 'Running timers have NULL ended_at. Duration computed on stop. One active timer per user enforced.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000005', 'schema_doc', 'dependencies', 'Dependency Graph',
 'blocking_item_id → blocked_item_id relationship. dependency_type (blocks/relates). Same project constraint enforced.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000006', 'schema_doc', 'activity_log', 'Activity Audit Trail',
 'entity_type + entity_id + action + field_name/old_value/new_value. Immutable append-only log. timestamp is Unix seconds.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000007', 'schema_doc', 'general', 'Soft Delete Pattern',
 'All tables have deleted_at column. ALWAYS filter WHERE deleted_at IS NULL in queries. Preserves audit trail.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000008', 'schema_doc', 'general', 'Audit Columns',
 'All mutable tables have: created_at, created_by, updated_at, updated_by. Tracks full change history.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000009', 'schema_doc', 'general', 'UUID Primary Keys',
 'All IDs are TEXT storing UUID v4. Compare as strings. Enables distributed/offline creation.',
 100, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000010', 'schema_doc', 'swim_lanes', 'Swim Lanes',
 'Custom Kanban columns per project. Position field for ordering. Status mapping to work item statuses.',
 100, strftime('%s','now'), strftime('%s','now'));

-- Query Patterns (Priority 90) - 8 entries
INSERT OR IGNORE INTO pm_llm_context (id, context_type, category, title, content, example_sql, example_description, priority, created_at, updated_at)
VALUES
('11111111-1111-1111-1111-000000000011', 'query_pattern', 'work_items', 'Project Hierarchy',
 'Recursive query to get full work item tree',
 'WITH RECURSIVE hierarchy AS (SELECT * FROM pm_work_items WHERE parent_id IS NULL UNION ALL SELECT wi.* FROM pm_work_items wi JOIN hierarchy h ON wi.parent_id = h.id) SELECT * FROM hierarchy WHERE deleted_at IS NULL',
 'Returns all work items in hierarchical order starting from top-level projects',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000012', 'query_pattern', 'dependencies', 'Find Blocked Items',
 'Query items blocked by other items',
 'SELECT wi.* FROM pm_work_items wi JOIN pm_dependencies d ON d.blocked_item_id = wi.id WHERE d.dependency_type = ''blocks'' AND d.deleted_at IS NULL AND wi.deleted_at IS NULL',
 'Returns work items that are blocked by dependencies',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000013', 'query_pattern', 'sprints', 'Sprint Velocity',
 'Calculate completed story points in a sprint',
 'SELECT SUM(story_points) as velocity FROM pm_work_items WHERE sprint_id = ?1 AND status = ''done'' AND deleted_at IS NULL',
 'Returns total story points completed in a sprint for velocity tracking',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000014', 'query_pattern', 'time_entries', 'Time Summary',
 'Sum time spent per work item',
 'SELECT work_item_id, SUM(duration_seconds) as total_seconds FROM pm_time_entries WHERE deleted_at IS NULL GROUP BY work_item_id',
 'Returns total time tracked for each work item',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000015', 'query_pattern', 'activity_log', 'Recent Activity',
 'Get recent changes across all entities',
 'SELECT * FROM pm_activity_log ORDER BY timestamp DESC LIMIT 50',
 'Returns 50 most recent activity log entries for dashboard',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000016', 'query_pattern', 'work_items', 'User Workload',
 'Count active items per assignee',
 'SELECT assignee_id, COUNT(*) as item_count FROM pm_work_items WHERE status != ''done'' AND deleted_at IS NULL GROUP BY assignee_id',
 'Returns workload distribution across team members',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000017', 'query_pattern', 'dependencies', 'Dependency Chain',
 'Find transitive dependency path',
 'WITH RECURSIVE deps AS (SELECT * FROM pm_dependencies WHERE blocking_item_id = ?1 UNION SELECT d.* FROM pm_dependencies d JOIN deps ON d.blocking_item_id = deps.blocked_item_id) SELECT * FROM deps',
 'Returns full chain of dependencies for an item (used for cycle detection)',
  90, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000018', 'query_pattern', 'work_items', 'Backlog Items',
 'Get unassigned items ordered by priority',
 'SELECT * FROM pm_work_items WHERE sprint_id IS NULL AND deleted_at IS NULL ORDER BY position ASC',
 'Returns backlog items in priority order for sprint planning',
  90, strftime('%s','now'), strftime('%s','now'));

-- Business Rules (Priority 80) - 5 entries
INSERT OR IGNORE INTO pm_llm_context (id, context_type, category, title, content, priority, created_at, updated_at)
VALUES
('11111111-1111-1111-1111-000000000019', 'business_rule', 'work_items', 'Sprint Assignment',
 'Only stories and tasks can be assigned to sprints. Epics and projects cannot be sprint-assigned.',
  80, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000020', 'business_rule', 'time_entries', 'Timer Exclusivity',
 'Maximum one running timer per user (ended_at IS NULL). Must stop current timer before starting new one.',
  80, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000021', 'business_rule', 'comments', 'Comment Ownership',
 'Only comment author can edit or delete their comments (author_id check required).',
  80, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000022', 'business_rule', 'dependencies', 'Same-Project Constraint',
 'Both work items in a dependency must belong to same project. Cross-project dependencies not allowed.',
  80, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000023', 'business_rule', 'work_items', 'Status Transitions',
 'Valid status flow: todo → in_progress → review → done. Blocked can be set from any status. Customizable per project.',
  80, strftime('%s','now'), strftime('%s','now'));

-- Instructions (Priority 70) - 5 entries
INSERT OR IGNORE INTO pm_llm_context (id, context_type, category, title, content, priority, created_at, updated_at)
VALUES
('11111111-1111-1111-1111-000000000024', 'instruction', 'general', 'Filter Deleted Records',
 'Always include WHERE deleted_at IS NULL in queries to exclude soft-deleted records.',
  70, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000025', 'instruction', 'work_items', 'Use Position for Ordering',
 'Use ORDER BY position ASC for display ordering in lists and boards. Position is user-managed.',
  70, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000026', 'instruction', 'general', 'UUID Comparison',
 'Compare UUIDs as TEXT strings (string equality). SQLite stores them as TEXT.',
  70, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000027', 'instruction', 'general', 'Limit Results',
 'Always use LIMIT in queries to prevent unbounded result sets. Default limit: 100.',
  70, strftime('%s','now'), strftime('%s','now')),

('11111111-1111-1111-1111-000000000028', 'instruction', 'activity_log', 'Use Activity Log for History',
 'Query pm_activity_log for change history. Do not query historical snapshots or maintain separate audit tables.',
  70, strftime('%s','now'), strftime('%s','now'));
```

**Run migration**:
```bash
sqlx migrate run
```

**Verify**:
```bash
sqlite3 data/tenants/test-tenant/main.db "SELECT COUNT(*) FROM pm_llm_context;"
# Should return: 28
```

---

### Part 3: Models

#### Step 3.1: Create LLM Context Model

**Create**: `backend/crates/pm-core/src/models/llm_context.rs`

```rust
use chrono::{DateTime, Utc};
use uuid::Uuid;

/// LLM context entry for self-documenting database
#[derive(Debug, Clone, PartialEq, Eq)]
pub struct LlmContext {
    pub id: Uuid,
    pub context_type: LlmContextType, // enum: schema_doc, query_pattern, business_rule, instruction, example
    pub category: String,      // "work_items", "sprints", "general", etc.
    pub title: String,
    pub content: String,
    pub example_sql: Option<String>,
    pub example_description: Option<String>,
    pub priority: i32, // Higher = more important (100=schema, 90=queries, 80=rules, 70=instructions)
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub deleted_at: Option<DateTime<Utc>>,
}
```

**Also create**: `backend/crates/pm-core/src/models/llm_context_type.rs`

```rust
use std::str::FromStr;

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum LlmContextType {
    SchemaDoc,
    QueryPattern,
    BusinessRule,
    Example,
    Instruction,
}

impl LlmContextType {
    pub fn as_str(&self) -> &'static str {
        match self {
            Self::SchemaDoc => "schema_doc",
            Self::QueryPattern => "query_pattern",
            Self::BusinessRule => "business_rule",
            Self::Example => "example",
            Self::Instruction => "instruction",
        }
    }
}

impl FromStr for LlmContextType {
    type Err = String;

    fn from_str(value: &str) -> Result<Self, Self::Err> {
        match value {
            "schema_doc" => Ok(Self::SchemaDoc),
            "query_pattern" => Ok(Self::QueryPattern),
            "business_rule" => Ok(Self::BusinessRule),
            "example" => Ok(Self::Example),
            "instruction" => Ok(Self::Instruction),
            _ => Err(format!("Unknown LlmContextType: {value}")),
        }
    }
}
```

**Update**: `backend/crates/pm-core/src/models/mod.rs`

Add:
```rust
pub mod llm_context;
pub mod llm_context_type;
pub use llm_context::LlmContext;
pub use llm_context_type::LlmContextType;
```

**Verification**: `cargo check -p pm-core`

---

### Part 4: Repositories

#### Step 4.1: Add Activity Log Repository Config

**File**: `backend/crates/pm-config/src/config.rs`

Add to the `Config` struct:

```rust
/// Activity log retention configuration
#[derive(Debug, Clone, serde::Deserialize)]
pub struct ActivityLogConfig {
    /// Number of days to retain activity logs (default: 90)
    #[serde(default = "default_retention_days")]
    pub retention_days: u32,

    /// Cleanup interval in hours (default: 24)
    #[serde(default = "default_cleanup_interval_hours")]
    pub cleanup_interval_hours: u32,
}

fn default_retention_days() -> u32 {
    90
}

fn default_cleanup_interval_hours() -> u32 {
    24
}

impl Default for ActivityLogConfig {
    fn default() -> Self {
        Self {
            retention_days: default_retention_days(),
            cleanup_interval_hours: default_cleanup_interval_hours(),
        }
    }
}

// Add to main Config struct:
pub struct Config {
    // ... existing fields ...

    #[serde(default)]
    pub activity_log: ActivityLogConfig,
}
```

**Verification**: `cargo check -p pm-config`

---

#### Step 4.2: Enhance Activity Log Repository

**File**: `backend/crates/pm-db/src/repositories/activity_log_repository.rs`

Add pagination methods (NO inline tests):

```rust
impl ActivityLogRepository {
    // ... existing methods ...

    /// Find activity for an entity with pagination
    /// Returns (entries, total_count)
    pub async fn find_by_entity_paginated<'e, E>(
        executor: E,
        entity_type: &str,
        entity_id: Uuid,
        limit: i64,
        offset: i64,
    ) -> DbErrorResult<(Vec<ActivityLog>, i64)>
    where
        E: sqlx::Executor<'e, Database = sqlx::Sqlite>,
    {
        // Get total count for pagination
        let total_count: i64 = sqlx::query_scalar!(
            r#"
            SELECT COUNT(*) as "count: i64"
            FROM pm_activity_log
            WHERE entity_type = ?1
              AND entity_id = ?2
            "#,
            entity_type,
            entity_id.to_string(),
        )
        .fetch_one(executor)
        .await?;

        // Get paginated entries
        let entries = sqlx::query_as!(
            ActivityLog,
            r#"
            SELECT id, entity_type, entity_id, action,
                   field_name, old_value, new_value,
                   user_id, timestamp, comment
            FROM pm_activity_log
            WHERE entity_type = ?1
              AND entity_id = ?2
            ORDER BY timestamp DESC
            LIMIT ?3 OFFSET ?4
            "#,
            entity_type,
            entity_id.to_string(),
            limit,
            offset,
        )
        .fetch_all(executor)
        .await?;

        Ok((entries, total_count))
    }

    /// Delete activity older than the given cutoff date (for retention policy)
    pub async fn delete_older_than<'e, E>(
        executor: E,
        cutoff: DateTime<Utc>,
    ) -> DbErrorResult<u64>
    where
        E: sqlx::Executor<'e, Database = sqlx::Sqlite>,
    {
        let result = sqlx::query!(
            r#"
            DELETE FROM pm_activity_log
            WHERE timestamp < ?1
            "#,
            cutoff,
        )
        .execute(executor)
        .await?;

        Ok(result.rows_affected())
    }
}
```

**Verification**: `cargo check -p pm-db`

---

#### Step 4.3: Create LLM Context Repository

**Create**: `backend/crates/pm-db/src/repositories/llm_context_repository.rs`

```rust
use pm_core::{LlmContext, LlmContextType};
use crate::{DbError, Result as DbErrorResult};
use chrono::{DateTime, Utc};
use error_location::ErrorLocation;
use std::panic::Location;
use std::str::FromStr;
use uuid::Uuid;

pub struct LlmContextRepository;

impl LlmContextRepository {
    /// Find all LLM context entries (ordered by priority desc, then title)
    pub async fn list_all<'e, E>(executor: E) -> DbErrorResult<Vec<LlmContext>>
    where
        E: sqlx::Executor<'e, Database = sqlx::Sqlite>,
    {
        let rows = sqlx::query!(
            r#"
            SELECT id, context_type, category, title, content,
                   example_sql, example_description, priority,
                   created_at, updated_at, deleted_at
            FROM pm_llm_context
            WHERE deleted_at IS NULL
            ORDER BY priority DESC, title ASC
            "#
        )
        .fetch_all(executor)
        .await?;

        rows.into_iter()
            .map(|r| {
                let id = r.id.ok_or_else(|| DbError::Initialization {
                    message: "llm_context.id is NULL".to_string(),
                    location: ErrorLocation::from(Location::caller()),
                })?;

                Ok(LlmContext {
                    id: Uuid::parse_str(&id).map_err(|e| DbError::Initialization {
                        message: format!("Invalid UUID in llm_context.id: {e}"),
                        location: ErrorLocation::from(Location::caller()),
                    })?,
                    context_type: LlmContextType::from_str(&r.context_type).map_err(|_| {
                        DbError::Initialization {
                            message: format!("Invalid context_type: {}", r.context_type),
                            location: ErrorLocation::from(Location::caller()),
                        }
                    })?,
                    category: r.category,
                    title: r.title,
                    content: r.content,
                    example_sql: r.example_sql,
                    example_description: r.example_description,
                    priority: r.priority as i32,
                    created_at: DateTime::<Utc>::from_timestamp(r.created_at, 0).ok_or_else(|| {
                        DbError::Initialization {
                            message: "Invalid created_at timestamp".to_string(),
                            location: ErrorLocation::from(Location::caller()),
                        }
                    })?,
                    updated_at: DateTime::<Utc>::from_timestamp(r.updated_at, 0).ok_or_else(|| {
                        DbError::Initialization {
                            message: "Invalid updated_at timestamp".to_string(),
                            location: ErrorLocation::from(Location::caller()),
                        }
                    })?,
                    deleted_at: r.deleted_at.and_then(|ts| DateTime::<Utc>::from_timestamp(ts, 0)),
                })
            })
            .collect()
    }

    /// Find entries by category (e.g., "work_items", "sprints")
    pub async fn list_filtered<'e, E>(
        executor: E,
        category: Option<&str>,
        context_type: Option<&str>,
        min_priority: Option<i32>,
    ) -> DbErrorResult<Vec<LlmContext>>
    where
        E: sqlx::Executor<'e, Database = sqlx::Sqlite>,
    {
        let rows = sqlx::query!(
            r#"
            SELECT id, context_type, category, title, content,
                   example_sql, example_description, priority,
                   created_at, updated_at, deleted_at
            FROM pm_llm_context
            WHERE deleted_at IS NULL
              AND (?1 IS NULL OR category = ?1)
              AND (?2 IS NULL OR context_type = ?2)
              AND (?3 IS NULL OR priority >= ?3)
            ORDER BY priority DESC, title ASC
            "#,
            category,
            context_type,
            min_priority
        )
        .fetch_all(executor)
        .await?;

        rows.into_iter()
            .map(|r| {
                let id = r.id.ok_or_else(|| DbError::Initialization {
                    message: "llm_context.id is NULL".to_string(),
                    location: ErrorLocation::from(Location::caller()),
                })?;

                Ok(LlmContext {
                    id: Uuid::parse_str(&id).map_err(|e| DbError::Initialization {
                        message: format!("Invalid UUID in llm_context.id: {e}"),
                        location: ErrorLocation::from(Location::caller()),
                    })?,
                    context_type: LlmContextType::from_str(&r.context_type).map_err(|_| {
                        DbError::Initialization {
                            message: format!("Invalid context_type: {}", r.context_type),
                            location: ErrorLocation::from(Location::caller()),
                        }
                    })?,
                    category: r.category,
                    title: r.title,
                    content: r.content,
                    example_sql: r.example_sql,
                    example_description: r.example_description,
                    priority: r.priority as i32,
                    created_at: DateTime::<Utc>::from_timestamp(r.created_at, 0).ok_or_else(|| {
                        DbError::Initialization {
                            message: "Invalid created_at timestamp".to_string(),
                            location: ErrorLocation::from(Location::caller()),
                        }
                    })?,
                    updated_at: DateTime::<Utc>::from_timestamp(r.updated_at, 0).ok_or_else(|| {
                        DbError::Initialization {
                            message: "Invalid updated_at timestamp".to_string(),
                            location: ErrorLocation::from(Location::caller()),
                        }
                    })?,
                    deleted_at: r.deleted_at.and_then(|ts| DateTime::<Utc>::from_timestamp(ts, 0)),
                })
            })
            .collect()
    }
}
```

**Update**: `backend/crates/pm-db/src/repositories/mod.rs`

Add:
```rust
pub mod llm_context_repository;
pub use llm_context_repository::LlmContextRepository;
```

**Verification**: `cargo check -p pm-db`

---

### Part 5: Handlers

#### Step 5.1: Create Activity Log Handler

**Create**: `backend/crates/pm-ws/src/handlers/activity_log.rs`

```rust
use crate::handlers::{
    authorization::check_permission,
    context::HandlerContext,
    db_ops::db_read,
    response_builder::build_activity_log_list_response,
};
use crate::{Result as WsErrorResult, WsError};
use pm_core::Permission;
use pm_db::{
    ActivityLogRepository, CommentRepository, DependencyRepository, ProjectRepository,
    SprintRepository, TimeEntryRepository, WorkItemRepository,
};
use pm_proto::{GetActivityLogRequest, WebSocketMessage};
use error_location::ErrorLocation;
use std::panic::Location;
use uuid::Uuid;

/// Valid entity types for activity log queries
const VALID_ENTITY_TYPES: &[&str] = &[
    "work_item",
    "sprint",
    "comment",
    "time_entry",
    "dependency",
    "project",
];

/// Handle GetActivityLogRequest with pagination and access control
pub async fn handle_get_activity_log(
    req: GetActivityLogRequest,
    ctx: HandlerContext,
) -> WsErrorResult<WebSocketMessage> {
    log::debug!("{} GetActivityLog starting", ctx.log_prefix());

    // 1. Validate entity_type is in allowed set
    if !VALID_ENTITY_TYPES.contains(&req.entity_type.as_str()) {
        return Err(WsError::ValidationError {
            message: format!(
                "Invalid entity_type '{}'. Must be one of: {:?}",
                req.entity_type, VALID_ENTITY_TYPES
            ),
            field: Some("entity_type".to_string()),
            location: ErrorLocation::from(Location::caller()),
        });
    }

    // 2. Parse and validate entity_id
    let entity_id = Uuid::parse_str(&req.entity_id).map_err(|_| WsError::ValidationError {
        message: format!("Invalid UUID format for entity_id: {}", req.entity_id),
        field: Some("entity_id".to_string()),
        location: ErrorLocation::from(Location::caller()),
    })?;

    // 3. SECURITY: Verify user has access to the entity's project
    let project_id = db_read(&ctx, "get_entity_project_id", || async {
        get_entity_project_id(&ctx, &req.entity_type, entity_id).await
    })
    .await?;

    // 4. Authorization
    check_permission(&ctx, project_id, Permission::View).await?;

    // 5. Validate and clamp pagination params
    let limit = req.limit.clamp(1, 100) as i64;
    let offset = req.offset.max(0) as i64;

    // 6. Query with pagination (uses circuit breaker via db_ops wrapper)
    let (entries, total_count) = db_read(&ctx, "find_activity_by_entity", || async {
        ActivityLogRepository::find_by_entity_paginated(
            &ctx.pool,
            &req.entity_type,
            entity_id,
            limit,
            offset,
        )
        .await
        .map_err(WsError::from)
    })
    .await?;

    log::info!(
        "{} Found {} activity entries (total: {}) for {} {}",
        ctx.log_prefix(),
        entries.len(),
        total_count,
        req.entity_type,
        entity_id
    );

    // 7. Build response with correlation ID
    Ok(build_activity_log_list_response(
        &ctx.message_id,
        &entries,
        total_count,
        limit,
        offset,
    ))
}

/// Helper to resolve entity -> project for access control
async fn get_entity_project_id(
    ctx: &HandlerContext,
    entity_type: &str,
    entity_id: Uuid,
) -> WsErrorResult<Uuid> {
    match entity_type {
        "work_item" => {
            let work_item = WorkItemRepository::find_by_id(&ctx.pool, entity_id)
                .await
                .map_err(WsError::from)?;
            work_item
                .map(|wi| wi.project_id)
                .ok_or_else(|| WsError::NotFound {
                    message: format!("Work item {} not found", entity_id),
                    location: ErrorLocation::from(Location::caller()),
                })
        }
        "project" => {
            let repo = ProjectRepository::new(ctx.pool.clone());
            let project = repo.find_by_id(entity_id).await.map_err(WsError::from)?;
            project
                .map(|p| p.id)
                .ok_or_else(|| WsError::NotFound {
                    message: format!("Project {} not found", entity_id),
                    location: ErrorLocation::from(Location::caller()),
                })
        }
        "sprint" => {
            let repo = SprintRepository::new(ctx.pool.clone());
            let sprint = repo.find_by_id(entity_id).await.map_err(WsError::from)?;
            sprint
                .map(|s| s.project_id)
                .ok_or_else(|| WsError::NotFound {
                    message: format!("Sprint {} not found", entity_id),
                    location: ErrorLocation::from(Location::caller()),
                })
        }
        "comment" => {
            let repo = CommentRepository::new(ctx.pool.clone());
            let comment = repo.find_by_id(entity_id).await.map_err(WsError::from)?;
            let comment = comment.ok_or_else(|| WsError::NotFound {
                message: format!("Comment {} not found", entity_id),
                location: ErrorLocation::from(Location::caller()),
            })?;

            let work_item = WorkItemRepository::find_by_id(&ctx.pool, comment.work_item_id)
                .await
                .map_err(WsError::from)?;
            work_item
                .map(|wi| wi.project_id)
                .ok_or_else(|| WsError::NotFound {
                    message: format!("Work item {} not found", comment.work_item_id),
                    location: ErrorLocation::from(Location::caller()),
                })
        }
        "time_entry" => {
            let repo = TimeEntryRepository::new(ctx.pool.clone());
            let entry = repo.find_by_id(entity_id).await.map_err(WsError::from)?;
            let entry = entry.ok_or_else(|| WsError::NotFound {
                message: format!("Time entry {} not found", entity_id),
                location: ErrorLocation::from(Location::caller()),
            })?;

            let work_item = WorkItemRepository::find_by_id(&ctx.pool, entry.work_item_id)
                .await
                .map_err(WsError::from)?;
            work_item
                .map(|wi| wi.project_id)
                .ok_or_else(|| WsError::NotFound {
                    message: format!("Work item {} not found", entry.work_item_id),
                    location: ErrorLocation::from(Location::caller()),
                })
        }
        "dependency" => {
            let repo = DependencyRepository::new(ctx.pool.clone());
            let dep = repo.find_by_id(entity_id).await.map_err(WsError::from)?;
            let dep = dep.ok_or_else(|| WsError::NotFound {
                message: format!("Dependency {} not found", entity_id),
                location: ErrorLocation::from(Location::caller()),
            })?;

            let work_item = WorkItemRepository::find_by_id(&ctx.pool, dep.blocked_item_id)
                .await
                .map_err(WsError::from)?;
            work_item
                .map(|wi| wi.project_id)
                .ok_or_else(|| WsError::NotFound {
                    message: format!("Work item {} not found", dep.blocked_item_id),
                    location: ErrorLocation::from(Location::caller()),
                })
        }
        _ => Err(WsError::ValidationError {
            message: format!("Invalid entity_type: {}", entity_type),
            field: Some("entity_type".to_string()),
            location: ErrorLocation::from(Location::caller()),
        }),
    }
}
```

**Update**: `backend/crates/pm-ws/src/handlers/mod.rs`

Add:
```rust
pub mod activity_log;
```

**Verification**: `cargo check -p pm-ws`

---

#### Step 5.2: Create LLM Context Handler

**Create**: `backend/crates/pm-ws/src/handlers/llm_context.rs`

```rust
use crate::handlers::{
    context::HandlerContext,
    db_ops::db_read,
    response_builder::build_llm_context_list_response,
};
use crate::{Result as WsErrorResult, WsError};
use pm_db::LlmContextRepository;
use pm_proto::{GetLlmContextRequest, WebSocketMessage};

/// Handle GetLlmContextRequest - Public endpoint (no auth required)
pub async fn handle_get_llm_context(
    req: GetLlmContextRequest,
    ctx: HandlerContext,
) -> WsErrorResult<WebSocketMessage> {
    log::debug!("{} GetLlmContext starting", ctx.log_prefix());

    // No authentication required - LLM context is public documentation

    // Apply filters (priority: category > context_type > min_priority > all)
    let entries = if let Some(category) = req.category {
        db_read(&ctx, "find_llm_context_by_category", || async {
            LlmContextRepository::find_by_category(&ctx.pool, &category)
                .await
                .map_err(WsError::from)
        })
        .await?
    } else if let Some(context_type) = req.context_type {
        db_read(&ctx, "find_llm_context_by_type", || async {
            LlmContextRepository::find_by_type(&ctx.pool, &context_type)
                .await
                .map_err(WsError::from)
        })
        .await?
    } else if let Some(min_priority) = req.min_priority {
        db_read(&ctx, "find_llm_context_by_priority", || async {
            LlmContextRepository::find_by_priority_above(&ctx.pool, min_priority)
                .await
                .map_err(WsError::from)
        })
        .await?
    } else {
        db_read(&ctx, "find_all_llm_context", || async {
            LlmContextRepository::find_all(&ctx.pool)
                .await
                .map_err(WsError::from)
        })
        .await?
    };

    log::info!(
        "{} Returning {} LLM context entries",
        ctx.log_prefix(),
        entries.len()
    );

    Ok(build_llm_context_list_response(&ctx.message_id, &entries))
}
```

**Update**: `backend/crates/pm-ws/src/handlers/mod.rs`

Add:
```rust
pub mod llm_context;
```

**Verification**: `cargo check -p pm-ws`

---

### Part 6: Response Builders

**File**: `backend/crates/pm-ws/src/handlers/response_builder.rs`

Add both response builder functions:

```rust
use pm_proto::{ActivityLogList, ActivityLogEntry, LlmContextList, LlmContextEntry, Payload, WebSocketMessage};
use pm_core::{ActivityLog, LlmContext};

/// Build ActivityLogList response
pub fn build_activity_log_list_response(
    message_id: &str,
    entries: &[ActivityLog],
    total_count: i64,
    limit: i64,
    offset: i64,
) -> WebSocketMessage {
    let proto_entries: Vec<ActivityLogEntry> = entries
        .iter()
        .map(|activity| {
            // Parse changes_json to extract field-level details
            let (field_name, old_value, new_value) = parse_changes_json(&activity.changes_json);

            ActivityLogEntry {
                id: activity.id.to_string(),
                entity_type: activity.entity_type.clone(),
                entity_id: activity.entity_id.to_string(),
                action: activity.action.clone(),
                field_name,
                old_value,
                new_value,
                user_id: activity.user_id.to_string(),
                timestamp: activity.created_at.timestamp(),
                comment: None, // Could be extracted from changes_json if needed
            }
        })
        .collect();

    let has_more = (offset + limit) < total_count;

    WebSocketMessage {
        message_id: message_id.to_string(),
        timestamp: chrono::Utc::now().timestamp(),
        payload: Some(Payload::ActivityLogList(ActivityLogList {
            entries: proto_entries,
            total_count: total_count as i32,
            has_more,
        })),
    }
}

/// Parse changes_json to extract field-level change details
/// Returns (field_name, old_value, new_value)
fn parse_changes_json(
    changes_json: &Option<String>,
) -> (Option<String>, Option<String>, Option<String>) {
    // For now, return None - full parsing would require structured changes format
    // In production, changes_json would be structured like:
    // {"field":"title","old":"Old Title","new":"New Title"}
    (None, None, None)
}

/// Build LlmContextList response
pub fn build_llm_context_list_response(
    message_id: &str,
    entries: &[LlmContext],
) -> WebSocketMessage {
    let proto_entries: Vec<LlmContextEntry> = entries
        .iter()
        .map(|ctx| LlmContextEntry {
            id: ctx.id.to_string(),
            context_type: ctx.context_type.clone(),
            category: ctx.category.clone(),
            title: ctx.title.clone(),
            content: ctx.content.clone(),
            example_sql: ctx.example_sql.clone(),
            example_description: ctx.example_description.clone(),
            priority: ctx.priority,
        })
        .collect();

    WebSocketMessage {
        message_id: message_id.to_string(),
        timestamp: chrono::Utc::now().timestamp(),
        payload: Some(Payload::LlmContextList(LlmContextList {
            entries: proto_entries,
        })),
    }
}
```

**Verification**: `cargo check -p pm-ws`

---

### Part 7: Dispatcher Integration

**File**: `backend/crates/pm-ws/src/handlers/dispatcher.rs`

Add to the match statement in `dispatch_inner`:

```rust
Some(Payload::GetActivityLogRequest(req)) => {
    activity_log::handle_get_activity_log(req, ctx).await
}
Some(Payload::GetLlmContextRequest(req)) => {
    llm_context::handle_get_llm_context(req, ctx).await
}
```

**Verification**: `cargo check -p pm-ws && cargo test -p pm-ws`

---

### Part 8: Tests

#### Step 8.1: Create Activity Log Repository Tests

**Create**: `backend/crates/pm-db/src/repositories/tests/activity_log_repository_tests.rs`

```rust
use super::super::*;
use crate::test_helpers::*;
use pm_core::ActivityLog;
use chrono::Utc;
use uuid::Uuid;

#[tokio::test]
async fn test_find_by_entity_paginated() {
    let pool = setup_test_db().await;
    let entity_id = Uuid::new_v4();

    // Create 10 activity log entries
    for i in 0..10 {
        let activity = ActivityLog {
            id: Uuid::new_v4(),
            entity_type: "work_item".to_string(),
            entity_id,
            action: "updated".to_string(),
            changes_json: Some(format!(r#"{{"iteration":{}}}"#, i)),
            user_id: Uuid::new_v4(),
            created_at: Utc::now(),
        };
        ActivityLogRepository::create(&pool, &activity).await.unwrap();
    }

    // Test pagination: first page (limit 5, offset 0)
    let (entries, total) = ActivityLogRepository::find_by_entity_paginated(
        &pool,
        "work_item",
        entity_id,
        5,
        0,
    )
    .await
    .unwrap();

    assert_eq!(entries.len(), 5);
    assert_eq!(total, 10);

    // Test pagination: second page (limit 5, offset 5)
    let (entries, total) = ActivityLogRepository::find_by_entity_paginated(
        &pool,
        "work_item",
        entity_id,
        5,
        5,
    )
    .await
    .unwrap();

    assert_eq!(entries.len(), 5);
    assert_eq!(total, 10);
}

#[tokio::test]
async fn test_find_by_entity_paginated_empty_result() {
    let pool = setup_test_db().await;
    let entity_id = Uuid::new_v4();

    let (entries, total) = ActivityLogRepository::find_by_entity_paginated(
        &pool,
        "work_item",
        entity_id,
        10,
        0,
    )
    .await
    .unwrap();

    assert_eq!(entries.len(), 0);
    assert_eq!(total, 0);
}

#[tokio::test]
async fn test_delete_older_than() {
    let pool = setup_test_db().await;
    let entity_id = Uuid::new_v4();

    // Create old entry
    let old_activity = ActivityLog {
        id: Uuid::new_v4(),
        entity_type: "work_item".to_string(),
        entity_id,
        action: "created".to_string(),
        changes_json: None,
        user_id: Uuid::new_v4(),
        created_at: Utc::now() - chrono::Duration::days(100),
    };
    ActivityLogRepository::create(&pool, &old_activity).await.unwrap();

    // Create recent entry
    let recent_activity = ActivityLog {
        id: Uuid::new_v4(),
        entity_type: "work_item".to_string(),
        entity_id,
        action: "updated".to_string(),
        changes_json: None,
        user_id: Uuid::new_v4(),
        created_at: Utc::now(),
    };
    ActivityLogRepository::create(&pool, &recent_activity).await.unwrap();

    // Delete entries older than 90 days
    let cutoff = Utc::now() - chrono::Duration::days(90);
    let deleted = ActivityLogRepository::delete_older_than(&pool, cutoff)
        .await
        .unwrap();

    assert_eq!(deleted, 1); // Only old entry deleted

    // Verify recent entry still exists
    let (entries, _) = ActivityLogRepository::find_by_entity_paginated(
        &pool,
        "work_item",
        entity_id,
        10,
        0,
    )
    .await
    .unwrap();

    assert_eq!(entries.len(), 1);
    assert_eq!(entries[0].id, recent_activity.id);
}

#[tokio::test]
async fn test_pagination_ordering() {
    let pool = setup_test_db().await;
    let entity_id = Uuid::new_v4();

    // Create entries with known order
    let mut created_ids = Vec::new();
    for _ in 0..3 {
        tokio::time::sleep(std::time::Duration::from_millis(10)).await;
        let activity = ActivityLog {
            id: Uuid::new_v4(),
            entity_type: "work_item".to_string(),
            entity_id,
            action: "updated".to_string(),
            changes_json: None,
            user_id: Uuid::new_v4(),
            created_at: Utc::now(),
        };
        created_ids.push(activity.id);
        ActivityLogRepository::create(&pool, &activity).await.unwrap();
    }

    // Fetch should return newest first (DESC order)
    let (entries, _) = ActivityLogRepository::find_by_entity_paginated(
        &pool,
        "work_item",
        entity_id,
        10,
        0,
    )
    .await
    .unwrap();

    assert_eq!(entries.len(), 3);
    assert_eq!(entries[0].id, created_ids[2]); // Newest first
    assert_eq!(entries[2].id, created_ids[0]); // Oldest last
}
```

**Update**: `backend/crates/pm-db/src/repositories/tests/mod.rs`

Add:
```rust
mod activity_log_repository_tests;
```

**Verification**: `cargo test -p pm-db -- activity_log`

---

#### Step 8.2: Create LLM Context Repository Tests

**Create**: `backend/crates/pm-db/src/repositories/tests/llm_context_repository_tests.rs`

```rust
use super::super::*;
use crate::test_helpers::*;
use pm_core::LlmContext;
use chrono::Utc;
use uuid::Uuid;

#[tokio::test]
async fn test_find_all_returns_ordered_by_priority() {
    let pool = setup_test_db().await;

    // Create entries with different priorities
    let high_priority = create_test_llm_context(&pool, "schema_doc", "test", 100).await;
    let low_priority = create_test_llm_context(&pool, "instruction", "test", 70).await;

    let entries = LlmContextRepository::find_all(&pool).await.unwrap();

    assert!(entries.len() >= 2);
    // High priority should come first
    let high_idx = entries.iter().position(|e| e.id == high_priority.id).unwrap();
    let low_idx = entries.iter().position(|e| e.id == low_priority.id).unwrap();
    assert!(high_idx < low_idx);
}

#[tokio::test]
async fn test_find_by_category_filters_correctly() {
    let pool = setup_test_db().await;

    create_test_llm_context(&pool, "schema_doc", "work_items", 100).await;
    create_test_llm_context(&pool, "schema_doc", "sprints", 100).await;

    let entries = LlmContextRepository::find_by_category(&pool, "work_items")
        .await
        .unwrap();

    assert!(entries.iter().all(|e| e.category == "work_items"));
}

#[tokio::test]
async fn test_find_by_type_filters_correctly() {
    let pool = setup_test_db().await;

    create_test_llm_context(&pool, "query_pattern", "test", 90).await;
    create_test_llm_context(&pool, "schema_doc", "test", 100).await;

    let entries = LlmContextRepository::find_by_type(&pool, "query_pattern")
        .await
        .unwrap();

    assert!(entries.iter().all(|e| e.context_type == "query_pattern"));
}

#[tokio::test]
async fn test_find_by_priority_above_filters_correctly() {
    let pool = setup_test_db().await;

    create_test_llm_context(&pool, "schema_doc", "test", 100).await;
    create_test_llm_context(&pool, "instruction", "test", 70).await;

    let entries = LlmContextRepository::find_by_priority_above(&pool, 80)
        .await
        .unwrap();

    assert!(entries.iter().all(|e| e.priority >= 80));
}

// Helper to create test LLM context entry
async fn create_test_llm_context(
    pool: &sqlx::SqlitePool,
    context_type: &str,
    category: &str,
    priority: i32,
) -> LlmContext {
    let entry = LlmContext {
        id: Uuid::new_v4(),
        context_type: context_type.to_string(),
        category: category.to_string(),
        title: format!("Test {} {}", context_type, Uuid::new_v4()),
        content: "Test content".to_string(),
        example_sql: None,
        example_description: None,
        priority,
        created_at: Utc::now(),
        updated_at: Utc::now(),
        deleted_at: None,
    };

    sqlx::query!(
        r#"
        INSERT INTO pm_llm_context
        (id, context_type, category, title, content, priority, created_at, updated_at)
        VALUES (?1, ?2, ?3, ?4, ?5, ?6, ?7, ?8)
        "#,
        entry.id,
        entry.context_type,
        entry.category,
        entry.title,
        entry.content,
        entry.priority,
        entry.created_at,
        entry.updated_at,
    )
    .execute(pool)
    .await
    .unwrap();

    entry
}
```

**Update**: `backend/crates/pm-db/src/repositories/tests/mod.rs`

Add:
```rust
mod llm_context_repository_tests;
```

**Verification**: `cargo test -p pm-db -- llm_context`

---

#### Step 8.3: Create Activity Log Handler Tests

**Create**: `backend/crates/pm-ws/tests/activity_log_handler_tests.rs`

```rust
use pm_ws::handlers::activity_log::handle_get_activity_log;
use pm_proto::{GetActivityLogRequest, web_socket_message::Payload};
use pm_core::ActivityLog;
use pm_db::ActivityLogRepository;
use chrono::Utc;
use uuid::Uuid;

mod common;
use common::*;

#[tokio::test]
async fn test_invalid_entity_type_returns_validation_error() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-1");

    let req = GetActivityLogRequest {
        entity_type: "invalid_type".to_string(),
        entity_id: Uuid::new_v4().to_string(),
        limit: 10,
        offset: 0,
    };

    let result = handle_get_activity_log(req, ctx).await;
    assert!(result.is_err());

    let err = result.unwrap_err();
    assert!(err.to_string().contains("Invalid entity_type"));
}

#[tokio::test]
async fn test_invalid_uuid_returns_validation_error() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-2");

    let req = GetActivityLogRequest {
        entity_type: "work_item".to_string(),
        entity_id: "not-a-uuid".to_string(),
        limit: 10,
        offset: 0,
    };

    let result = handle_get_activity_log(req, ctx).await;
    assert!(result.is_err());

    let err = result.unwrap_err();
    assert!(err.to_string().contains("Invalid UUID"));
}

#[tokio::test]
async fn test_pagination_clamps_limit_to_max_100() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;

    // Create test work item first
    let work_item = create_test_work_item(&pool).await;

    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-3");

    let req = GetActivityLogRequest {
        entity_type: "work_item".to_string(),
        entity_id: work_item.id.to_string(),
        limit: 500, // Should be clamped to 100
        offset: 0,
    };

    let result = handle_get_activity_log(req, ctx).await;
    assert!(result.is_ok());

    // Response should succeed (actual clamping verified by repository)
    let response = result.unwrap();
    assert!(matches!(response.payload, Some(Payload::ActivityLogList(_))));
}

#[tokio::test]
async fn test_returns_paginated_entries() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;

    // Create test work item
    let work_item = create_test_work_item(&pool).await;

    // Create 10 activity log entries
    for i in 0..10 {
        let activity = ActivityLog {
            id: Uuid::new_v4(),
            entity_type: "work_item".to_string(),
            entity_id: work_item.id,
            action: "updated".to_string(),
            changes_json: Some(format!(r#"{{"iteration":{}}}"#, i)),
            user_id: Uuid::new_v4(),
            created_at: Utc::now(),
        };
        ActivityLogRepository::create(&pool, &activity).await.unwrap();
    }

    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-4");

    // Request first page
    let req = GetActivityLogRequest {
        entity_type: "work_item".to_string(),
        entity_id: work_item.id.to_string(),
        limit: 5,
        offset: 0,
    };

    let result = handle_get_activity_log(req, ctx).await;
    assert!(result.is_ok());

    let response = result.unwrap();
    if let Some(Payload::ActivityLogList(list)) = response.payload {
        assert_eq!(list.entries.len(), 5);
        assert_eq!(list.total_count, 10);
        assert!(list.has_more);
    } else {
        panic!("Expected ActivityLogList payload");
    }
}

#[tokio::test]
async fn test_empty_entity_returns_empty_list() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;

    // Create test work item but no activity
    let work_item = create_test_work_item(&pool).await;

    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-5");

    let req = GetActivityLogRequest {
        entity_type: "work_item".to_string(),
        entity_id: work_item.id.to_string(),
        limit: 10,
        offset: 0,
    };

    let result = handle_get_activity_log(req, ctx).await;
    assert!(result.is_ok());

    let response = result.unwrap();
    if let Some(Payload::ActivityLogList(list)) = response.payload {
        assert_eq!(list.entries.len(), 0);
        assert_eq!(list.total_count, 0);
        assert!(!list.has_more);
    } else {
        panic!("Expected ActivityLogList payload");
    }
}

#[tokio::test]
async fn test_entity_not_found_returns_error() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-6");

    let req = GetActivityLogRequest {
        entity_type: "work_item".to_string(),
        entity_id: Uuid::new_v4().to_string(), // Non-existent
        limit: 10,
        offset: 0,
    };

    let result = handle_get_activity_log(req, ctx).await;
    assert!(result.is_err());

    let err = result.unwrap_err();
    assert!(err.to_string().contains("not found"));
}
```

**Verification**: `cargo test -p pm-ws -- activity_log`

---

#### Step 8.4: Create LLM Context Handler Tests

**Create**: `backend/crates/pm-ws/tests/llm_context_handler_tests.rs`

```rust
use pm_ws::handlers::llm_context::handle_get_llm_context;
use pm_proto::{GetLlmContextRequest, web_socket_message::Payload};

mod common;
use common::*;

#[tokio::test]
async fn test_returns_all_when_no_filters() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;

    // Seed data should exist from migration
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-1");

    let req = GetLlmContextRequest {
        category: None,
        context_type: None,
        min_priority: None,
    };

    let result = handle_get_llm_context(req, ctx).await;
    assert!(result.is_ok());

    let response = result.unwrap();
    if let Some(Payload::LlmContextList(list)) = response.payload {
        assert_eq!(list.entries.len(), 28); // All seed entries
    } else {
        panic!("Expected LlmContextList payload");
    }
}

#[tokio::test]
async fn test_filters_by_category() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-2");

    let req = GetLlmContextRequest {
        category: Some("work_items".to_string()),
        context_type: None,
        min_priority: None,
    };

    let result = handle_get_llm_context(req, ctx).await;
    assert!(result.is_ok());

    let response = result.unwrap();
    if let Some(Payload::LlmContextList(list)) = response.payload {
        assert!(!list.entries.is_empty());
        assert!(list.entries.iter().all(|e| e.category == "work_items"));
    } else {
        panic!("Expected LlmContextList payload");
    }
}

#[tokio::test]
async fn test_filters_by_context_type() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-3");

    let req = GetLlmContextRequest {
        category: None,
        context_type: Some("query_pattern".to_string()),
        min_priority: None,
    };

    let result = handle_get_llm_context(req, ctx).await;
    assert!(result.is_ok());

    let response = result.unwrap();
    if let Some(Payload::LlmContextList(list)) = response.payload {
        assert_eq!(list.entries.len(), 8); // 8 query patterns
        assert!(list.entries.iter().all(|e| e.context_type == "query_pattern"));
    } else {
        panic!("Expected LlmContextList payload");
    }
}

#[tokio::test]
async fn test_filters_by_min_priority() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-4");

    let req = GetLlmContextRequest {
        category: None,
        context_type: None,
        min_priority: Some(90),
    };

    let result = handle_get_llm_context(req, ctx).await;
    assert!(result.is_ok());

    let response = result.unwrap();
    if let Some(Payload::LlmContextList(list)) = response.payload {
        assert_eq!(list.entries.len(), 18); // 10 schema + 8 query patterns
        assert!(list.entries.iter().all(|e| e.priority >= 90));
    } else {
        panic!("Expected LlmContextList payload");
    }
}

#[tokio::test]
async fn test_no_auth_required() {
    let (pool, circuit_breaker) = setup_test_infrastructure().await;

    // Create context with any user (no special permissions needed)
    let ctx = create_test_handler_context(pool, circuit_breaker, "test-msg-5");

    let req = GetLlmContextRequest {
        category: None,
        context_type: None,
        min_priority: None,
    };

    // Should succeed without auth checks
    let result = handle_get_llm_context(req, ctx).await;
    assert!(result.is_ok());
}
```

**Verification**: `cargo test -p pm-ws -- llm_context`

---

## Session 70.1 Completion Checklist

After completing all steps:

- [ ] `cargo check -p pm-proto` passes
- [ ] `cargo check -p pm-core` passes
- [ ] `cargo check -p pm-db` passes
- [ ] `cargo check -p pm-ws` passes
- [ ] `cargo test -p pm-db -- activity_log` passes
- [ ] `cargo test -p pm-db -- llm_context` passes
- [ ] `cargo test -p pm-ws -- activity_log` passes
- [ ] `cargo test -p pm-ws -- llm_context` passes
- [ ] `cargo clippy --workspace -- -D warnings` passes
- [ ] `sqlx migrate run` succeeds
- [ ] Query: `SELECT COUNT(*) FROM pm_llm_context;` returns 28

### Files Created (10)

**Source files (5):**
- `backend/crates/pm-ws/src/handlers/activity_log.rs`
- `backend/crates/pm-core/src/models/llm_context.rs`
- `backend/crates/pm-db/src/repositories/llm_context_repository.rs`
- `backend/crates/pm-db/migrations/20260127000001_seed_llm_context.sql`
- `backend/crates/pm-ws/src/handlers/llm_context.rs`

**Test files (5):**
- `backend/crates/pm-db/src/repositories/tests/activity_log_repository_tests.rs`
- `backend/crates/pm-db/src/repositories/tests/llm_context_repository_tests.rs`
- `backend/crates/pm-ws/tests/activity_log_handler_tests.rs`
- `backend/crates/pm-ws/tests/llm_context_handler_tests.rs`
- (Test module declarations in existing `mod.rs` files)

### Files Modified (10)
- `proto/messages.proto` - Add ALL activity log + LLM context messages
- `backend/crates/pm-db/src/repositories/activity_log_repository.rs` - Add pagination
- `backend/crates/pm-config/src/config.rs` - Activity log retention config
- `backend/crates/pm-core/src/models/mod.rs` - Export LlmContext
- `backend/crates/pm-db/src/repositories/mod.rs` - Export LlmContextRepository
- `backend/crates/pm-db/src/repositories/tests/mod.rs` - Declare test modules
- `backend/crates/pm-ws/src/handlers/mod.rs` - Export new handlers
- `backend/crates/pm-ws/src/handlers/dispatcher.rs` - Wire new handlers
- `backend/crates/pm-ws/src/handlers/response_builder.rs` - Add response builders
- `backend/crates/pm-ws/src/handlers/work_item.rs` - Add activity broadcast

---

## Implementation Order Summary

1. **Proto Messages** - ALL messages defined first (fields 140-145)
2. **Database Migrations** - LLM context seed data (28 entries)
3. **Models** - LlmContext domain model
4. **Repositories** - Activity log pagination + LLM context queries
5. **Handlers** - Activity log + LLM context query endpoints
6. **Response Builders** - Proto response construction
7. **Dispatcher** - Wire handlers to routing
8. **Tests** - Repository and handler tests

This order ensures:
✅ Proto definitions exist before anything uses them
✅ Migrations run before code queries the data
✅ Models exist before repositories use them
✅ Repositories exist before handlers use them
✅ Handlers exist before dispatcher routes to them
✅ Tests verify everything after implementation

---

## Next Session

**Session 70.2** will implement:
- Toast notification service (IToastService, ToastService)
- Operation spinner component
- Activity feed UI components (ActivityFeed, ActivityItem, ActivityFeedSkeleton)
- Activity log models and converters
- WebSocket client activity methods
